<수정사항>
1. python_yolov5와 c++_onnx차이줄이기
인식결과가 차이가나 차이를 줄임
python_yolov5에서는 90%이상 컵인식이 잘되었는데
c++_onnx 정확도가 떨어짐
=>onnxDetectImage.py를 만들어 객체감지확인함(C:/images/cups.jpg의 76%와 바운딩박스 확인)
=>c++프로그램에 적용하여 테스트

<필요한 모듈 설치>
[date] C++에서 날짜와 시간 관련 기능을 제공
C:\>git clone https://github.com/HowardHinnant/date.git
C:\>cd date
C:\date>mkdir build
C:\date>cd build
C:\date\build>cmake -G "Visual Studio 16 2019" ..
-- Configuring done (7.7s)
-- Generating done (0.7s)
-- Build files have been written to: C:/date/build
C:\date\build>cmake --build .

[ONNX (Open Neural Network Exchange)] 머신러닝 모델을 교환하는 데 사용
C:\>git clone https://github.com/onnx/onnx.git
C:\>cd onnx
C:\onnx>mkdir build
C:\onnx>cd build
C:\onnx\build>cmake -G "Visual Studio 16 2019" ..
-- Configuring done (22.4s)
-- Generating done (1.0s)
-- Build files have been written to: C:/onnx/build
C:\onnx\build>cmake --build .
C:\onnx>protoc --proto_path=onnx --cpp_out=build onnx/onnx-operators.proto
=> "C:\onnx\build\onnx\onnx-operators.pb.h", "C:\onnx\build\onnx\onnx-operators.pb.cc" 생성

[onnx.pb.h 생성하기]
C:\>protoc --version
libprotoc 26.1
C:\>protoc --proto_path=C:\onnx\onnx --cpp_out=C:\onnx\onnx C:\onnx\onnx\onnx.proto
=>"C:\onnx\onnx\onnx.pb.h" 생성

[vcpkg 설치 및 업그레이드]
Git을 사용하여 vcpkg를 클론
C:\>git clone https://github.com/microsoft/vcpkg.git
vcpkg 부트스트랩
C:\>cd vcpkg
C:\vcpkg>.\bootstrap-vcpkg.bat
C:\>cd vcpkg

[Protocol Buffers (protobuf)] Google에서 개발한 데이터 직렬화(serialization) 포맷
C:\vcpkg>.\vcpkg.exe install protobuf
"C:\vcpkg\packages\protobuf_x64-windows"
find_package(protobuf CONFIG REQUIRED)
target_link_libraries(main PRIVATE protobuf::libprotoc protobuf::libprotobuf protobuf::libprotobuf-lite)

[GSL(Gnu Scientific Library)] 과학적 계산과 수학적 작업을 지원하는 오픈 소스 라이브러리
C:\vcpkg>.\vcpkg.exe install gsl
"C:\vcpkg\packages\gsl_x64-windows"
find_package(GSL REQUIRED)
target_link_libraries(main PRIVATE GSL::gsl GSL::gslcblas)

[flatbuffers] Google에서 개발한 직렬화 라이브러리
C:\>git clone https://github.com/google/flatbuffers.git
C:\>cd flatbuffers
C:\flatbuffers>mkdir build
C:\flatbuffers>cd build
C:\flatbuffers\build>cmake -G "Visual Studio 16 2019" ..
-- Configuring done (6.9s)
-- Generating done (0.1s)
-- Build files have been written to: C:/flatbuffers/build
C:\flatbuffers\build>cmake --build .

1) CMakeLists.txt
cmake_minimum_required(VERSION 3.14)
project(Project1 LANGUAGES CXX CUDA)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

set(CMAKE_TOOLCHAIN_FILE "C:/vcpkg/scripts/buildsystems/vcpkg.cmake" CACHE FILEPATH "Path to vcpkg toolchain file")
set(CMAKE_PREFIX_PATH "C:/vcpkg/packages" "C:/Qt/6.7.1/msvc2019_64" "C:/opencv/build")

find_package(Qt6 REQUIRED COMPONENTS Widgets Core Gui)
find_package(OpenCV REQUIRED COMPONENTS core imgproc highgui cudaarithm cudafilters cudawarping cudacodec cudafeatures2d cudaimgproc dnn)
find_package(CUDA REQUIRED)

# ONNX 설정
# C:\>protoc --proto_path=C:\onnx\onnx --cpp_out=C:\onnx\onnx C:\onnx\onnx\onnx.proto
set(ONNX_ROOT "C:/onnx")
set(ONNX_DIR "C:/onnx/build") # ONNXConfig.cmake
include_directories("${ONNX_ROOT}")
link_directories("${ONNX_ROOT}/build/lib/pkgconfig")
# Protobuf 설정
set(Protobuf_ROOT "${CMAKE_PREFIX_PATH}/protobuf_x64-windows")
set(Protobuf_INCLUDE_DIR "${Protobuf_ROOT}/include/google/protobuf")
set(Protobuf_LIB "${Protobuf_ROOT}/bin")
include_directories(${Protobuf_INCLUDE_DIR})
link_directories("${Protobuf_LIB}")
#onnx.pb.h생성(실패)
#find_package(Protobuf REQUIRED)
# Protobuf 설치 경로 설정 (경로는 실제 Protobuf 설치 경로로 수정해야 합니다)
# set(CMAKE_PREFIX_PATH "C:/vcpkg/packages/protobuf_x64-windows" ${CMAKE_PREFIX_PATH})
# Set Protobuf include directories
#include_directories(${PROTOBUF_INCLUDE_DIRS})
# Protobuf files
#set(PROTO_FILES
#    ${CMAKE_CURRENT_SOURCE_DIR}/onnx/onnx.proto
#)
# Generate Protobuf C++ files
#protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
# Create library from generated files
#add_library(onnx_proto ${PROTO_SRCS} ${PROTO_HDRS})
# Link against Protobuf
#target_link_libraries(onnx_proto ${PROTOBUF_LIBRARIES})

# GSL 설정 추가
set(GSL_ROOT "${CMAKE_PREFIX_PATH}/gsl_x64-windows")
set(GSL_INCLUDE_DIR "${GSL_ROOT}/include")
set(GSL_LIBRARY "${GSL_ROOT}/lib")
set(GSL_CBLAS_LIBRARY "${GSL_LIBRARY}/gslcblas.lib")
include_directories(${GSL_INCLUDE_DIR})
link_directories("${GSL_LIBRARY}" "${GSL_CBLAS_LIBRARY}")

# LibTorch 설정
set(TORCH_ROOT "C:/libtorch")
set(Torch_DIR "${TORCH_ROOT}/share/cmake/Torch")
include_directories("${TORCH_ROOT}/include")
link_directories("${TORCH_ROOT}/lib")
find_package(Torch REQUIRED)

# ONNX Runtime 설정
set(ONNX_RUNTIME_ROOT "C:/onnxruntime")
include_directories( 
    "${ONNX_RUNTIME_ROOT}"
    "${ONNX_RUNTIME_ROOT}/cmake/build/_deps/safeint-src"
    "${ONNX_RUNTIME_ROOT}/cmake/build/_deps/mp11-src/include"
    "${ONNX_RUNTIME_ROOT}/cmake/build/_deps/onnx-src/onnx"
    "${ONNX_RUNTIME_ROOT}/cmake/build"
    "${ONNX_RUNTIME_ROOT}/build"
    "${ONNX_RUNTIME_ROOT}/onnxruntime"
    "${ONNX_RUNTIME_ROOT}/build/_deps/mp11-src/include"
    "${ONNX_RUNTIME_ROOT}/build/_deps/safeint-src"
    "${ONNX_RUNTIME_ROOT}/include/onnxruntime"
    "${ONNX_RUNTIME_ROOT}/include/onnxruntime/core/session"
    )
link_directories("${ONNX_RUNTIME_ROOT}/cmake/build/Debug")
find_library(ONNXRUNTIME_LIB NAMES custom_op_local_function PATHS "${ONNX_RUNTIME_ROOT}/cmake/build/Debug")
if (ONNXRUNTIME_LIB)
    message(STATUS "Found ONNX Runtime library: ${ONNXRUNTIME_LIB}")
else()
    message(FATAL_ERROR "ONNX Runtime library not found")
endif()
set(ONNX_RUNTIME_LIB_DIR "${ONNX_RUNTIME_ROOT}/build/${CMAKE_BUILD_TYPE}")

# IPP 설정
set(IPP_ROOT "C:/Program Files (x86)/Intel/oneAPI/ipp/2021.11")
include_directories("${IPP_ROOT}/include")
link_directories("${IPP_ROOT}/lib")

# GStreamer 설정
set(GSTREAMER_ROOT "C:/gstreamer/1.0/msvc_x86_64")
include_directories(
    "${GSTREAMER_ROOT}/include/gstreamer-1.0"
    "${GSTREAMER_ROOT}/include/glib-2.0"
    "${GSTREAMER_ROOT}/lib/glib-2.0/include"
)
link_directories("${GSTREAMER_ROOT}/lib")

# IPLIB 설정
set(IPLIB_ROOT "C:/myLab/Project1/Project1/imageProcessingLib")
include_directories("${IPLIB_ROOT}")
link_directories(
    "${IPLIB_ROOT}/build/lib/${CMAKE_BUILD_TYPE}"
    "${IPLIB_ROOT}/build/bin/${CMAKE_BUILD_TYPE}"
    "${IPLIB_ROOT}/build/${CMAKE_BUILD_TYPE}"
)

# Abseil 라이브러리 설정
# Google이 개발하고 관리하는 오픈 소스 C++ 라이브러리
set(ABSEIL_ROOT "C:/abseil-cpp")
include_directories("${ABSEIL_ROOT}")
link_directories("${ABSEIL_ROOT}/build/lib")

# flatbuffers 설정
set(FLATBUFFERS_ROOT "C:/flatbuffers")
include_directories("${FLATBUFFERS_ROOT}/include")
link_directories("${FLATBUFFERS_ROOT}/build/Debug")

# date 설정
set(DATE_ROOT "C:/date")
include_directories("${DATE_ROOT}/include")
link_directories("${DATE_ROOT}/build/Debug")

# CUDA 아키텍처 설정
set(CUDA_ARCHITECTURES "86")
message(STATUS "CUDA Architectures set to: ${CUDA_ARCHITECTURES}")

# CUDA 파일 설정
set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} -std=c++14 --expt-relaxed-constexpr -gencode arch=compute_86,code=sm_86)

# CUDA 파일 컴파일 및 라이브러리 생성
cuda_add_library(image_processing
    imageProcessing.cu
)

# Qt 래핑 파일 생성
qt6_wrap_cpp(MOC_FILES
    MainWindow.h
    ImageProcessor.h
    DetectDialog.h
)

# 라이브러리 링크
target_link_libraries(image_processing
    ippcc.lib
    ippcore.lib
    ippvm.lib
    ipps.lib
    ippi.lib
    ippcv.lib
    nppial
    nppicc
    nppidei
    nppif
    nppig
    nppim
    nppist
    nppisu
    nppitc
    npps
    imageProcessingLib
    flatbuffers
    date
    gstreamer-1.0.lib
    gobject-2.0.lib
    glib-2.0.lib
    gstapp-1.0.lib
    gstbase-1.0.lib
    gstvideo-1.0.lib
)

# 실행 파일 추가
add_executable(Project1
    main.cpp
    MainWindow.cpp
    MainWindow.h
    MainWindow.ui
    ImageProcessor.cpp
    ImageProcessor.h
    ${MOC_FILES}
)

# 라이브러리 링크
target_link_libraries(Project1
    Qt6::Widgets
    Qt6::Core
    Qt6::Gui
    ${OpenCV_LIBS}
    image_processing
    imageProcessingLib
    ${CUDA_LIBRARIES}
    ${CUDNN_LIBRARIES}
    ${GSTREAMER_LIBRARIES}
    ${TORCH_LIBRARIES}  # LibTorch 링크
    flatbuffers
    date
    ${ONNX_RUNTIME_LIB}
    ${ONNX_LIB}
    ${Protobuf_LIB}
    ${ONNX_DIR}/onnx/onnx-operators.pb.cc
)

# 빌드 후 TARGET_FILE_DIR 출력
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E echo "TARGET_FILE_DIR for Project1: $<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E echo "$<TARGET_FILE_DIR:Project1>" > "Project1_dir.txt"
)

# 실행 파일 출력 디렉토리 설정
set_target_properties(Project1 PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY_DEBUG "${CMAKE_BINARY_DIR}/Debug"
    RUNTIME_OUTPUT_DIRECTORY_RELEASE "${CMAKE_BINARY_DIR}/Release"
)

file(COPY "C:/myLab/Project1/Project1/imageProcessingLib/build/Debug/imageProcessingLib.dll"
     DESTINATION "${CMAKE_BINARY_DIR}/Debug"
)

# 디버그 빌드에서의 OpenCV opencv_world DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/x64/vc16/bin/opencv_world4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Debug opencv_world DLL to output directory"
)

# 릴리스 빌드에서의 OpenCV opencv_world DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/x64/vc16/bin/opencv_world4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Release opencv_world DLL to output directory"
)

# 디버그 빌드에서의 OpenCV DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_dnn4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudaarithm4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudaimgproc4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudafilters4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_imgcodecs4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_core4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_imgproc4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Debug DLLs to output directory"
)

# 릴리스 빌드에서의 OpenCV DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_dnn4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudaarithm4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudaimgproc4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudafilters4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_imgcodecs4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_core4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_imgproc4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Release DLLs to output directory"
)

# 파일 인코딩 설정 추가
add_compile_options("$<$<CXX_COMPILER_ID:MSVC>:/utf-8>")

# OpenMP 설정
find_package(OpenMP REQUIRED)
if(OpenMP_CXX_FOUND)
    target_link_libraries(Project1 OpenMP::OpenMP_CXX)
endif()

if (MSVC)
    set_property(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} PROPERTY VS_STARTUP_PROJECT Project1)

    # Debug 빌드
    set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG} /MDd")
    set(CMAKE_C_FLAGS_DEBUG "${CMAKE_C_FLAGS_DEBUG} /MDd")

    # Release 빌드
    set(CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE} /MD")
    set(CMAKE_C_FLAGS_RELEASE "${CMAKE_C_FLAGS_RELEASE} /MD")

    # 반복자 디버그 레벨 설정
    add_compile_definitions(
        $<$<CONFIG:Debug>:_ITERATOR_DEBUG_LEVEL=2>
        $<$<CONFIG:Release>:_ITERATOR_DEBUG_LEVEL=0>
    )
endif()


2) yolov5로 학습된 best.pt를 best.onnx파일로 export (python 3.12.3 myenv c:/myenv가상환경)
# C:/yolov5/runs/train/exp30/weights/best.pt (인식률이나오는걸로고름)
# C:\myLab\Project1\Project1\python\myTorchScript.py
import sys
import torch
import onnx
import onnxruntime as ort
import os

# 디버깅 정보 저장 리스트
debug_info = []

def log_debug_info(message):
    debug_info.append(message)

# YOLOv5 경로를 추가합니다
sys.path.append('C:/yolov5')
log_debug_info("YOLOv5 path added to system path.")

# 모델 경로 설정
model_path = 'C:/yolov5/runs/train/exp30/weights/best.pt'
log_debug_info(f"Model path set to: {model_path}")

# CUDA가 사용 가능한 경우, CUDA로 로드하고, 그렇지 않으면 CPU로 로드합니다
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
log_debug_info(f"Using device: {device}")

# 모델 로드
try:
    log_debug_info("Attempting to load the model...")
    model = torch.load(model_path, map_location=device, weights_only=False)['model'].float()
    model.to(device)
    model.eval()
    log_debug_info("Model loaded and set to evaluation mode.")
except Exception as e:
    log_debug_info(f"Error loading model: {str(e)}")
    sys.exit()

# 더미 입력 텐서 생성 (CUDA 또는 CPU에 맞게 설정)
dummy_input = torch.randn(1, 3, 640, 640).to(device)
log_debug_info(f"Dummy input tensor created with shape: {dummy_input.shape}")

# ONNX로 모델 내보내기
onnx_path = 'C:/myLab/Project1/Project1/python/best.onnx'
log_debug_info(f"Export path set to: {onnx_path}")

try:
    log_debug_info("Attempting to export model to ONNX format...")
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        verbose=True,
        opset_version=12,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    if os.path.exists(onnx_path):
        log_debug_info(f"ONNX file successfully created at: {onnx_path}")
    else:
        log_debug_info(f"Failed to create ONNX file at: {onnx_path}")
except Exception as e:
    log_debug_info(f"Error exporting model to ONNX: {str(e)}")
    sys.exit()

# ONNX Runtime 버전과 CUDA 버전 출력
try:
    log_debug_info(f"ONNX Runtime version: {ort.__version__}")
except Exception as e:
    log_debug_info(f"Error getting ONNX Runtime version: {str(e)}")

try:
    log_debug_info(f"CUDA version: {torch.version.cuda}")
except Exception as e:
    log_debug_info(f"Error getting CUDA version: {str(e)}")

# ONNX 모델 검증
try:
    log_debug_info("Attempting to validate the ONNX model...")
    onnx_model = onnx.load(onnx_path)
    onnx.checker.check_model(onnx_model)
    log_debug_info("ONNX model is valid.")
except Exception as e:
    log_debug_info(f"Error validating ONNX model: {str(e)}")
    sys.exit()

# ONNX Runtime 세션 생성 (GPU 사용)
try:
    log_debug_info("Creating ONNX Runtime session...")
    providers = ['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']
    ort_session = ort.InferenceSession(onnx_path, providers=providers)
    log_debug_info(f"ONNX Runtime session created with {'GPU' if torch.cuda.is_available() else 'CPU'} support.")
except Exception as e:
    log_debug_info(f"Error creating ONNX Runtime session: {str(e)}")
    sys.exit()

# 더미 입력 준비
dummy_input_np = dummy_input.cpu().numpy()
log_debug_info(f"Dummy input numpy array created with shape: {dummy_input_np.shape}")

# 추론 실행
try:
    log_debug_info("Running inference...")
    outputs = ort_session.run(None, {'input': dummy_input_np})
    log_debug_info("Inference completed. Outputs:")
    log_debug_info(str(outputs))
except Exception as e:
    log_debug_info(f"Error running inference: {str(e)}")

# 모든 디버깅 정보를 출력
print("\n--- Debug Information ---")
for info in debug_info:
    print(info)

2) C:\ObjectDetect\onnxDetectImage.py 파일만들어서 객체감지 테스트 (Python 3.12.3 c:/pythonEnv 가상환경)
#C:\ObjectDetect\onnxDetectImage.py
#76% 인식률 나옴
import cv2
import numpy as np
import onnxruntime as ort

# ONNX 모델 경로와 이미지 경로
model_path = "C:/myLab/Project1/Project1/python/best.onnx"
image_path = "C:/ObjectDetect/cups.jpg"

# 모델 불러오기
session = ort.InferenceSession(model_path)

# 클래스 이름 (모델 학습 시 사용된 클래스 목록을 여기에 정의)
class_names = ["cup"]

# 이미지 불러오기
image = cv2.imread(image_path)
orig_img = image.copy()
h, w = image.shape[:2]

# 이미지 전처리
input_size = 640  # YOLOv5 기본 입력 사이즈
image = cv2.resize(image, (input_size, input_size))
image = image.transpose(2, 0, 1)  # HWC to CHW
image = np.expand_dims(image, axis=0)
image = image.astype(np.float32) / 255.0

# ONNX 모델 추론
input_name = session.get_inputs()[0].name
outputs = session.run(None, {input_name: image})

# YOLOv5는 여러 스케일에서 감지된 결과를 반환합니다.
predictions = outputs[0]

# 후처리: NMS (Non-Maximum Suppression)
def nms(boxes, scores, iou_threshold):
    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=0.5, nms_threshold=iou_threshold)
    return indices

def process_predictions(predictions, h, w):
    boxes = []
    confidences = []
    class_ids = []

    for pred in predictions:
        # 박스 좌표 (x_center, y_center, width, height)
        pred = pred.reshape(-1, 6)  # reshape to (num_boxes, 6) if necessary

        for box in pred:
            # 박스 좌표와 confidence 값 추출
            x_center, y_center, width, height, score = box[:5]
            class_scores = box[5:]

            # confidence 및 class_id 추출
            class_id = np.argmax(class_scores)
            score = float(score)

            if score >= 0.5:  # confidence threshold
                # 좌표를 원본 이미지 크기로 변환
                x = int((x_center - width / 2) * w / input_size)
                y = int((y_center - height / 2) * h / input_size)
                width = int(width * w / input_size)
                height = int(height * h / input_size)

                boxes.append([x, y, width, height])
                confidences.append(score)
                class_ids.append(class_id)

    # NMS 적용
    indices = nms(boxes, confidences, 0.4)

    # indices가 비어 있지 않은지 확인
    if len(indices) > 0:
        indices = indices.flatten()  # 2D 배열을 1D 배열로 변환
        results = [(class_ids[i], boxes[i], confidences[i]) for i in indices]
    else:
        results = []  # 감지된 객체가 없는 경우 빈 리스트 반환
    
    return results

# 결과 처리
results = process_predictions(predictions, h, w)

# 결과 표시
for class_id, box, confidence in results:
    if class_id < len(class_names):  # class_id가 class_names의 범위 내에 있는지 확인
        x, y, width, height = box
        label = f"{class_names[class_id]}: {confidence:.2f}"
        cv2.rectangle(orig_img, (x, y), (x + width, y + height), (0, 255, 0), 2)
        cv2.putText(orig_img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    else:
        print(f"Invalid class_id {class_id}. It exceeds the number of class names.")

# 이미지 출력
cv2.imshow("Detected Objects", orig_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
