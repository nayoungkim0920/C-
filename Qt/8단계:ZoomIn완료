1. MainWindow.h
//MainWindow.h
#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#include <QMainWindow>
#include <QImage>
#include <QPixmap>
#include <QFileDialog>
#include <QMessageBox>
#include <QInputDialog>
#include <opencv2/opencv.hpp>
#include "ImageProcessor.h"
#include "ui_MainWindow.h"

QT_BEGIN_NAMESPACE
namespace Ui { class MainWindow; }
QT_END_NAMESPACE

class MainWindow : public QMainWindow
{
    Q_OBJECT

public:
    MainWindow(QWidget* parent = nullptr);
    ~MainWindow();

private slots:
    void openFile();
    void saveFile();
    void rotateImage();
    void zoomInImage();
    void zoomOutImage();
    void grayScale();
    void gaussianBlur();
    void cannyEdges();
    void medianFilter();
    void laplacianFilter();
    void bilateralFilter();
    void sobelFilter();
    void exitApplication();
    void redoAction();
    void undoAction();
    void first();
    void displayImage(cv::Mat image, QLabel* label);
    void handleImageProcessed(QVector<ImageProcessor::ProcessingResult> results);

private:
    Ui::MainWindow* ui;

    cv::Mat currentImage;

    cv::Mat currentImageOpenCV;
    cv::Mat currentImageIPP;
    cv::Mat currentImageCUDA;
    cv::Mat currentImageCUDAKernel;

    ImageProcessor* imageProcessor;

    double scaleFactor;

    cv::Mat initialImageOpenCV;
    cv::Mat initialImageIPP;
    cv::Mat initialImageCUDA;
    cv::Mat initialImageCUDAKernel;

    cv::Mat previousImageOpenCV;
    cv::Mat previousImageIPP;
    cv::Mat previousImageCUDA;
    cv::Mat previousImageCUDAKernel;

    void connectActions();
    void connectImageProcessor();
    void setInitialWindowGeometry();

    //template<typename Func, typename... Args>
    //inline void applyImageProcessing(Func func, Args&&... args);
};

#endif // MAINWINDOW_H

2. MainWindow.cpp
//MainWindow.cpp
#include "MainWindow.h"

MainWindow::MainWindow(QWidget* parent)
    : QMainWindow(parent)
    , ui(new Ui::MainWindow)
    , imageProcessor(new ImageProcessor)
    , scaleFactor(1.0)
{
    ui->setupUi(this);

    ui->label_opencv_title->setText(QString("OpenCV"));
    ui->label_ipp_title->setText(QString("IPP"));
    ui->label_cuda_title->setText(QString("CUDA"));
    ui->label_cudakernel_title->setText(QString("CUDA Kernel"));

    connectActions();

    //처음로딩 후 필터처리가 너무 느려 추가함
    imageProcessor->initializeCUDA();

    connectImageProcessor();

    setInitialWindowGeometry();
}

MainWindow::~MainWindow()
{
    delete ui;
    delete imageProcessor;
}

void MainWindow::openFile()
{
    QString fileName = QFileDialog::getOpenFileName(this, tr("Open Image"), "", tr("Image Files (*.png *.jpg *.bmp *.jpeg);;All Files (*)"));
    if (!fileName.isEmpty()) {
        cv::Mat loadedImage;
        if (imageProcessor->openImage(fileName.toStdString(), loadedImage)) {

            currentImageOpenCV = loadedImage.clone();
            currentImageIPP = loadedImage.clone();
            currentImageCUDA = loadedImage.clone();
            currentImageCUDAKernel = loadedImage.clone();

            initialImageOpenCV = currentImageOpenCV.clone();
            initialImageIPP = currentImageIPP.clone();
            initialImageCUDA = currentImageCUDA.clone();
            initialImageCUDAKernel = currentImageCUDAKernel.clone();

            displayImage(initialImageOpenCV, ui->label_opencv);
            displayImage(initialImageIPP, ui->label_ipp);
            displayImage(initialImageCUDA, ui->label_cuda);
            displayImage(initialImageCUDAKernel, ui->label_cudakernel);
        }
        else {
            QMessageBox::critical(this, tr("Error"), tr("Failed to open image file"));
        }
    }
}

void MainWindow::saveFile()
{
    //if (!currentImage.empty()) {
    //    QString filePath = QFileDialog::getSaveFileName(this, tr("Save Image"), "", tr("Images (*.png *.jpg *.bmp)"));
    //    if (!filePath.isEmpty()) {
    //        if (!imageProcessor->saveImage(filePath.toStdString(), currentImage)) {
    //            QMessageBox::critical(this, tr("Error"), tr("Failed to save image"));
    //        }
    //    }
    //}
    //else {
    //    QMessageBox::critical(this, tr("Error"), tr("No image to save"));
    //}
}

void MainWindow::rotateImage()
{
    //QtConcurrent::run([this]() {
    //    if (!currentImage.empty()) {
    //        imageProcessor->rotateImage(currentImage);
    //    }
    //});
    ////applyImageProcessing(&ImageProcessor::rotateImage, currentImage);
}

void MainWindow::zoomInImage()
{
    QtConcurrent::run([this]() {
        if (!currentImageOpenCV.empty()) {
            imageProcessor->zoominImage(currentImageOpenCV
                , currentImageIPP
                , currentImageCUDA
                , currentImageCUDAKernel
                , scaleFactor = 1.25);
        }
    });
    //applyImageProcessing(&ImageProcessor::zoominImage, currentImage, scaleFactor=1.25);
}

void MainWindow::zoomOutImage()
{
    //QtConcurrent::run([this]() {
    //    if (!currentImage.empty()) {
    //        imageProcessor->zoomoutImage(currentImage, scaleFactor = 0.8);
    //    }
    //    });
    //applyImageProcessing(&ImageProcessor::zoomoutImage, currentImage, scaleFactor = 0.8);
}

void MainWindow::grayScale()
{
    QtConcurrent::run([this]() {
        
        imageProcessor->grayScale(currentImageOpenCV
        , currentImageIPP
        , currentImageCUDA
        , currentImageCUDAKernel);

        });

    //applyImageProcessing(&ImageProcessor::grayScale, currentImage);
}

void MainWindow::gaussianBlur()
{
    bool ok;
    int kernelSize = QInputDialog::getInt(this,
        tr("Gaussian Blur"),
        tr("Enter kernel size (odd nubmber):"),
        5, 1, 101, 2, &ok);

    if (ok) {
        QtConcurrent::run([this, kernelSize]() {
            if (!currentImage.empty()) {
                imageProcessor->gaussianBlur(currentImage, kernelSize);
            }
            });
        //applyImageProcessing(&ImageProcessor::gaussianBlur, currentImage, kernelSize);
    }
}

void MainWindow::cannyEdges()
{
    QtConcurrent::run([this]() {
        if (!currentImage.empty()) {
            imageProcessor->cannyEdges(currentImage);
        }
        });
    //applyImageProcessing(&ImageProcessor::cannyEdges, currentImage);
}

void MainWindow::medianFilter()
{
    QtConcurrent::run([this]() {
        if (!currentImage.empty()) {
            imageProcessor->medianFilter(currentImage);
        }
        });
    //applyImageProcessing(&ImageProcessor::medianFilter, currentImage);
}

void MainWindow::laplacianFilter()
{
    QtConcurrent::run([this]() {
        if (!currentImage.empty()) {
            imageProcessor->laplacianFilter(currentImage);
        }
        });
    //applyImageProcessing(&ImageProcessor::laplacianFilter, currentImage);
}

void MainWindow::bilateralFilter()
{
    QtConcurrent::run([this]() {
        if (!currentImage.empty()) {
            imageProcessor->bilateralFilter(currentImage);
        }
        });
    //applyImageProcessing(&ImageProcessor::bilateralFilter, currentImage);
}

void MainWindow::sobelFilter()
{
    QtConcurrent::run([this]() {
        if (!currentImage.empty()) {
            imageProcessor->sobelFilter(currentImage);
        }
        });
    //applyImageProcessing(&ImageProcessor::)
}

void MainWindow::exitApplication()
{
    QApplication::quit();
}

void MainWindow::redoAction()
{
    if (imageProcessor->canRedoOpenCV()) {
        imageProcessor->redo();
    }
}

void MainWindow::undoAction()
{
    if (imageProcessor->canUndoOpenCV()) {
        imageProcessor->undo();
    }
}

void MainWindow::first()
{
    //초기 이미지로 되돌리기
    //if (!initialImage.empty()) {
    //    currentImage = initialImage.clone();

    //    displayImage(currentImage, ui->label_opencv);
    //    displayImage(currentImage, ui->label_ipp);
     //   displayImage(currentImage, ui->label_cuda);
     //   displayImage(currentImage, ui->label_cudakernel);

    //    imageProcessor->cleanUndoStack();
    //    imageProcessor->cleanRedoStack();
    //}
    //else {
    //    QMessageBox::warning(this,
   //         tr("Warning"),
   //         tr("No initial Image available."));
   //     return;
   // }
}

void MainWindow::displayImage(cv::Mat image, QLabel* label)
{
    QMetaObject::invokeMethod(this, [this, image, label]() {
        qDebug() << "displayImage() channels: " << image.channels();

        // 이미지 타입에 따라 QImage를 생성합니다.
        QImage qImage;
        if (image.type() == CV_8UC1) {
            qDebug() << "displayImage() type: grayscale CV_8UC1 Format_Grayscale8";
            qImage = QImage(image.data,
                image.cols,
                image.rows,
                static_cast<int>(image.step),
                QImage::Format_Grayscale8);
        }
        else if (image.type() == CV_8UC3) {
            qDebug() << "displayImage() type: BGR CV_8UC3 Format_RGB888";
            qImage = QImage(image.data,
                image.cols,
                image.rows,
                static_cast<int>(image.step),
                QImage::Format_RGB888).rgbSwapped();
        }
        else {
            qDebug() << "displayImage() type: not supported";
            return; // 지원하지 않는 이미지 타입은 처리하지 않음
        }

        // QLabel 위젯에 QPixmap으로 이미지를 설정합니다.
        QPixmap pixmap = QPixmap::fromImage(qImage);
        label->setPixmap(pixmap);
        label->setScaledContents(true);
        label->adjustSize();
        });
}

void MainWindow::handleImageProcessed(QVector<ImageProcessor::ProcessingResult> results)
{
    for (int i = 0; i < results.size(); ++i) {
        const auto& result = results[i];
        if (i == 0) {
            currentImageOpenCV = result.processedImage.clone();
            displayImage(result.processedImage, ui->label_opencv);
            ui->label_opencv_title->setText(QString("%1 %2 %3ms")
                .arg(result.processName)
                .arg(result.functionName)
                .arg(result.processingTime));
        }
        else if (i == 1) {
            currentImageIPP = result.processedImage;
            displayImage(result.processedImage, ui->label_ipp);
            ui->label_ipp_title->setText(QString("%1 %2 %3ms")
                .arg(result.processName)
                .arg(result.functionName)
                .arg(result.processingTime));
        }
        else if (i == 2) {
            currentImageCUDA= result.processedImage;
            displayImage(result.processedImage, ui->label_cuda);
            ui->label_cuda_title->setText(QString("%1 %2 %3ms")
                .arg(result.processName)
                .arg(result.functionName)
                .arg(result.processingTime));
        }
        else if (i == 3) {
            currentImageCUDAKernel = result.processedImage;
            displayImage(result.processedImage, ui->label_cudakernel);
            ui->label_cudakernel_title->setText(QString("%1 %2 %3ms")
                .arg(result.processName)
                .arg(result.functionName)
                .arg(result.processingTime));
        }
            
    }

    // 이미지 출력
    //displayImage(processedImage);

    // 상태 표시줄에 처리 시간 출력
    //statusBar()->showMessage(
    //    QString("%1 processed in %2 ms").arg(processName).arg(processingTimeMs));

}


void MainWindow::connectActions()
{
    connect(ui->actionOpen, &QAction::triggered, this, &MainWindow::openFile);
    connect(ui->actionSave, &QAction::triggered, this, &MainWindow::saveFile);
    connect(ui->actionExit, &QAction::triggered, this, &MainWindow::exitApplication);

    connect(ui->actionRotate, &QAction::triggered, this, &MainWindow::rotateImage);
    connect(ui->actionZoomIn, &QAction::triggered, this, &MainWindow::zoomInImage);
    connect(ui->actionZoomOut, &QAction::triggered, this, &MainWindow::zoomOutImage);
    connect(ui->actionRedo, &QAction::triggered, this, &MainWindow::redoAction);
    connect(ui->actionUndo, &QAction::triggered, this, &MainWindow::undoAction);

    connect(ui->actionGrayscale, &QAction::triggered, this, &MainWindow::grayScale);
    connect(ui->actionGaussianBlur, &QAction::triggered, this, &MainWindow::gaussianBlur);
    connect(ui->actionCannyEdges, &QAction::triggered, this, &MainWindow::cannyEdges);
    connect(ui->actionMedianFilter, &QAction::triggered, this, &MainWindow::medianFilter);
    connect(ui->actionLaplacianFilter, &QAction::triggered, this, &MainWindow::laplacianFilter);
    connect(ui->actionBilateralFilter, &QAction::triggered, this, &MainWindow::bilateralFilter);
    connect(ui->actionSobelFilter, &QAction::triggered, this, &MainWindow::sobelFilter);

    connect(ui->actionFirst, &QAction::triggered, this, &MainWindow::first);

}

void MainWindow::connectImageProcessor()
{
    // Connect ImageProcessor's signal to displayImage slot
    connect(imageProcessor, &ImageProcessor::imageProcessed, this, &MainWindow::handleImageProcessed);
}

void MainWindow::setInitialWindowGeometry()
{
    const int initialWidth = 800;
    const int initialHeight = 600;
    const int initialX = 100;
    const int initialY = 100;
    this->setGeometry(initialX, initialY, initialWidth, initialHeight);
}

//template<typename Func, typename ...Args>
//inline void MainWindow::applyImageProcessing(Func func, Args&& ...args)
//{
//    if (!currentImage.empty()) {
//        auto future = (imageProcessor->*func)(std::forward<Args>(args)...);
//        future.waitForFinished();
//        if (!future.result()) {
//            qDebug() << "Failed to apply" << Q_FUNC_INFO;
//        }
//    }
//    else {
//        qDebug() << "No image to process.";
//    }
//}

3. imageProcessor.h
//ImageProcessor.h
#ifndef IMAGEPROCESSOR_H
#define IMAGEPROCESSOR_H

//순서
//시스템 헤더 파일
//라이브러리 헤더 파일
//사용자 정의 헤더 파일

#include <QObject>
#include <QDebug>
#include <chrono>
#include <stack>
#include <vector>
#include <QMutex>
#include <QMutexLocker>
#include <QtConcurrent/QtConcurrent>

#include <opencv2/core.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/core/cuda.hpp>
#include <opencv2/cudaimgproc.hpp>
#include <opencv2/cudaarithm.hpp>
#include <opencv2/cudafilters.hpp>
#include <opencv2/cudawarping.hpp>

#include <ipp.h>
#include <ipp/ippcore.h>
#include <ipp/ippi.h>
#include <ipp/ippcc.h>
#include <ipp/ipps.h>
#include "imageProcessing.cuh"


class ImageProcessor : public QObject
{
    Q_OBJECT

public:
    explicit ImageProcessor(QObject* parent = nullptr);
    ~ImageProcessor();

    struct ProcessingResult {
        QString functionName;
        QString processName;
        cv::Mat processedImage;
        double processingTime;

        ProcessingResult() = default;
        ProcessingResult(const QString& functionName, const QString& processName, const cv::Mat& processedImage, double processingTime)
            : functionName(functionName), processName(processName), processedImage(processedImage), processingTime(processingTime) {}
    };

    bool openImage(const std::string& fileName, cv::Mat& image);
    bool saveImage(const std::string& fileName, const cv::Mat& image);

    QFuture<bool> rotateImage(cv::Mat& image);
    QFuture<bool> zoominImage(cv::Mat& imageOpenCV, cv::Mat& imageIPP, cv::Mat& imageCUDA, cv::Mat& imageCUDAKernel, double scaleFactor);
    QFuture<bool> zoomoutImage(cv::Mat& image, double scaleFactor);
    QFuture<bool> grayScale(cv::Mat& imageOpenCV, cv::Mat& imageIPP, cv::Mat& imageCUDA, cv::Mat& imageCUDAKernel);
    QFuture<bool> gaussianBlur(cv::Mat& image, int kernelSize);
    QFuture<bool> cannyEdges(cv::Mat& image);
    QFuture<bool> medianFilter(cv::Mat& image);
    QFuture<bool> laplacianFilter(cv::Mat& image);
    QFuture<bool> bilateralFilter(cv::Mat& image);
    QFuture<bool> sobelFilter(cv::Mat& image);

    bool canUndoOpenCV() const;
    bool canRedoOpenCV() const;

    void undo();
    void redo();

    void cleanUndoStack();
    void cleanRedoStack();

    void initializeCUDA();

    const cv::Mat& getLastProcessedImageOpenCV() const;
    const cv::Mat& getLastProcessedImageIPP() const;
    const cv::Mat& getLastProcessedImageCUDA() const;
    const cv::Mat& getLastProcessedImageCUDAKernel() const;

signals: //이벤트 발생을 알림
    void imageProcessed(QVector<ImageProcessor::ProcessingResult> results);
//slots: //이벤트를 처리하는 함수 지칭

private:

    cv::Mat lastProcessedImageOpenCV;
    cv::Mat lastProcessedImageIPP;
    cv::Mat lastProcessedImageCUDA;
    cv::Mat lastProcessedImageCUDAKernel;

    QMutex mutex;

    std::stack<cv::Mat> undoStackOpenCV;
    std::stack<cv::Mat> undoStackIPP;
    std::stack<cv::Mat> undoStackCUDA;
    std::stack<cv::Mat> undoStackCUDAKernel;

    std::stack<cv::Mat> redoStackOpenCV;
    std::stack<cv::Mat> redoStackIPP;
    std::stack<cv::Mat> redoStackCUDA;
    std::stack<cv::Mat> redoStackCUDAKernel;

    void pushToUndoStackOpenCV(const cv::Mat& image);
    void pushToUndoStackIPP(const cv::Mat& image);
    void pushToUndoStackCUDA(const cv::Mat& image);
    void pushToUndoStackCUDAKernel(const cv::Mat& image);

    void pushToRedoStackOpenCV(const cv::Mat& image);
    void pushToRedoStackIPP(const cv::Mat& image);
    void pushToRedoStackCUDA(const cv::Mat& image);
    void pushToRedoStackCUDAKernel(const cv::Mat& image);

    //bool grayScaleCUDA(cv::Mat& image);
    ProcessingResult grayScaleOpenCV(cv::Mat& image);
    ProcessingResult grayScaleIPP(cv::Mat& image);
    ProcessingResult grayScaleCUDA(cv::Mat& image);
    ProcessingResult grayScaleCUDAKernel(cv::Mat& image);

    ProcessingResult zoomInOpenCV(cv::Mat& image, double newWidth, double newHeight);
    ProcessingResult zoomInIPP(cv::Mat& image, double newWidth, double newHeight);
    ProcessingResult zoomInCUDA(cv::Mat& image, double newWidth, double newHeight);
    ProcessingResult zoomInCUDAKernel(cv::Mat& image, double newWidth, double newHeight);

    double getCurrentTimeMs();
};

#endif // IMAGEPROCESSOR_H

4.imageProessor.cpp
//ImageProcessor.cpp
#include "ImageProcessor.h"

ImageProcessor::ImageProcessor(QObject* parent) : QObject(parent)
{
}

ImageProcessor::~ImageProcessor()
{
}

bool ImageProcessor::openImage(const std::string& fileName, cv::Mat& image)
{
    image = cv::imread(fileName);
    if (image.empty()) {
        qDebug() << "Failed to open image: " << QString::fromStdString(fileName);
        return false;
    }
    return true;
}

bool ImageProcessor::saveImage(const std::string& fileName, const cv::Mat& image)
{
    if (!cv::imwrite(fileName, image)) {
        qDebug() << "Failed to save image: " << QString::fromStdString(fileName);
        return false;
    }
    return true;
}

QFuture<bool> ImageProcessor::rotateImage(cv::Mat& image)
{
    // 함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]() -> bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간 계산
            double startTime = getCurrentTimeMs();

            // 이미지를 CUDA를 이용하여 회전
            // imageProcessing.cuh/imagProessing.cu            
            callRotateImageCUDA(image);

            // CUDA 내장함수로  구현
            // #include <opencv2/cudawarping.hpp>
            //double angle = 90.0; // 회전할 각도 (예: 90도)

            // 이미지를 GPU 메모리에 업로드
            //cv::cuda::GpuMat gpuImage;
            //gpuImage.upload(image);

            // 회전 중심을 이미지의 중앙으로 설정
            //cv::Point2f center(gpuImage.cols / 2.0f, gpuImage.rows / 2.0f);

            // 회전 매트릭스 계산
            //cv::Mat rotationMatrix = cv::getRotationMatrix2D(center, angle, 1.0);

            // GPU에서 회전 수행
            //cv::cuda::GpuMat gpuRotatedImage;
            //cv::cuda::warpAffine(gpuImage, gpuRotatedImage, rotationMatrix, gpuImage.size());

            // 결과 이미지를 CPU 메모리로 다운로드
            //gpuRotatedImage.download(image);

            // 이미지 처리 끝

            // 이미지 처리 시간 측정
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //lastProcessedImage = image.clone();

            // 이미지 업데이트 및 시그널 발생
            //emit imageProcessed(image, processingTime, functionName);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while rotating image:" << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::zoomoutImage(cv::Mat& image, double scaleFactor)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, scaleFactor, functionName]() -> bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            if (scaleFactor <= 0) {
                qDebug() << "잘못된 축소 배율입니다.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            int newWidth = static_cast<int>(image.cols * scaleFactor);
            int newHeight = static_cast<int>(image.rows * scaleFactor);

            //openCV
            //cv::Mat zoomedImage;
            //cv::resize(image, zoomedImage, cv::Size(newWidth, newHeight), 0, 0, cv::INTER_LINEAR);

            //cuda내장함수
            //cv::cuda::GpuMat d_image, zoomedImage;
            //d_image.upload(image);

            //cv::cuda::resize(d_image, zoomedImage,
            //    cv::Size(newWidth, newHeight),
            //    0, 0, cv::INTER_LINEAR);

            //CUDA Kernel
            callResizeImageCUDA(image, newWidth, newHeight);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //zoomedImage.download(image); //cuda내장함수
            //image = zoomedImage.clone(); //openCV
            //lastProcessedImage = image.clone();

            //emit imageProcessed(image, processingTime, functionName); // 이미지 처리 완료 시그널 발생

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "이미지 축소 중 예외가 발생했습니다:" << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::zoominImage(cv::Mat& imageOpenCV
                                        , cv::Mat& imageIPP
                                        , cv::Mat& imageCUDA
                                        , cv::Mat& imageCUDAKernel
                                        , double scaleFactor)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this
                            , &imageOpenCV
                            , &imageIPP
                            , &imageCUDA
                            , &imageCUDAKernel
                            , scaleFactor
                            , functionName]() -> bool {

        QMutexLocker locker(&mutex);

        try {

            if (imageOpenCV.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            if (scaleFactor <= 0) {
                qDebug() << "잘못된 확대 배율입니다.";
                return false;
            }

            pushToUndoStackOpenCV(imageOpenCV.clone());
            pushToUndoStackIPP(imageIPP.clone());
            pushToUndoStackCUDA(imageCUDA.clone());
            pushToUndoStackCUDAKernel(imageCUDAKernel.clone());

            QVector<ProcessingResult> results;

            double newWidth = static_cast<int>(imageOpenCV.cols * scaleFactor);
            double newHeight = static_cast<int>(imageOpenCV.rows * scaleFactor);

            ProcessingResult outputOpenCV1 = zoomInOpenCV(imageOpenCV, newWidth, newHeight);
            lastProcessedImageOpenCV = outputOpenCV1.processedImage.clone();
            results.append(outputOpenCV1);

            ProcessingResult outputIPP = zoomInIPP(imageIPP, newWidth, newHeight);
            lastProcessedImageIPP = outputIPP.processedImage.clone();
            results.append(outputIPP);

            ProcessingResult outputCUDA = zoomInCUDA(imageCUDA, newWidth, newHeight);
            lastProcessedImageCUDA = outputCUDA.processedImage.clone();
            results.append(outputCUDA);

            ProcessingResult outputCUDAKernel = zoomInCUDAKernel(imageCUDAKernel, newWidth, newHeight);
            lastProcessedImageCUDAKernel = outputCUDAKernel.processedImage.clone();
            results.append(outputCUDAKernel);

            emit imageProcessed(results); // 이미지 처리 완료 시그널 발생

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "이미지 확대 중 예외가 발생했습니다:" << e.what();
            return false;
        }
        });
}


// QDebug에서 cv::Size를 출력할 수 있도록 변환 함수 작성
QDebug operator<<(QDebug dbg, const cv::Size& size) {
    dbg.nospace() << "Size(width=" << size.width << ", height=" << size.height << ")";
    return dbg.space();
}

// QDebug에서 cv::Mat의 타입을 출력할 수 있도록 변환 함수 작성
QDebug operator<<(QDebug dbg, const cv::Mat& mat) {
    dbg.nospace() << "Mat(type=" << mat.type() << ", size=" << mat.size() << ")";
    return dbg.space();
}

QFuture<bool> ImageProcessor::grayScale(cv::Mat& imageOpenCV
                                        , cv::Mat& imageIPP
                                        , cv::Mat& imageCUDA
                                        , cv::Mat& imageCUDAKernel)
{
    const char* functionName = __func__;

    return QtConcurrent::run([this
                            , &imageOpenCV
                            , &imageIPP
                            , &imageCUDA
                            , &imageCUDAKernel
                            , functionName]() -> bool {
        
        QMutexLocker locker(&mutex);

        try {
            if (imageOpenCV.channels() != 3 && imageOpenCV.channels() != 1) {
                qDebug() << "Input image must be a 3-channel BGR image or already grayscale.";
                return false;
            }

            if (imageOpenCV.channels() == 3) {
                pushToUndoStackOpenCV(imageOpenCV.clone());
                pushToUndoStackIPP(imageIPP.clone());
                pushToUndoStackCUDA(imageCUDA.clone());
                pushToUndoStackCUDAKernel(imageCUDAKernel.clone());

                QVector<ProcessingResult> results;

                ProcessingResult outputOpenCV = grayScaleOpenCV(imageOpenCV);
                lastProcessedImageOpenCV = outputOpenCV.processedImage.clone();
                results.append(outputOpenCV);

                ProcessingResult outputIPP = grayScaleIPP(imageIPP);
                lastProcessedImageIPP = outputIPP.processedImage.clone();
                results.append(outputIPP);

                ProcessingResult outputCUDA = grayScaleCUDA(imageCUDA);
                lastProcessedImageCUDA = outputCUDA.processedImage.clone();
                results.append(outputCUDA);

                ProcessingResult outputCUDAKernel = grayScaleCUDAKernel(imageCUDAKernel);
                lastProcessedImageCUDAKernel = outputCUDAKernel.processedImage.clone();
                results.append(outputCUDAKernel);

                emit imageProcessed(results);
            }
            else {
                pushToUndoStackOpenCV(imageOpenCV.clone());
                pushToUndoStackIPP(imageIPP.clone());
                pushToUndoStackCUDA(imageCUDA.clone());
                pushToUndoStackCUDAKernel(imageCUDAKernel.clone());

                lastProcessedImageOpenCV = imageOpenCV.clone();
                lastProcessedImageIPP = imageIPP.clone();
                lastProcessedImageCUDA = imageCUDA.clone();
                lastProcessedImageCUDAKernel = imageCUDAKernel.clone();
            }

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while converting to grayscale:" << e.what();
            return false;
        }
        });
}

/*bool ImageProcessor::grayScaleCUDA(cv::Mat& image)
{
    try {

        // CUDA 장치 설정
        cv::cuda::setDevice(0);

        // 입력 이미지를 CUDA GpuMat으로 업로드
        cv::cuda::GpuMat d_input;
        d_input.upload(image);

        // CUDA를 사용하여 그레이스케일로 변환
        cv::cuda::GpuMat d_output;
        cv::cuda::cvtColor(d_input, d_output, cv::COLOR_BGR2GRAY);

        // CUDA에서 호스트로 이미지 다운로드
        cv::Mat output;
        d_output.download(output);

        if (output.empty() || output.type() != CV_8UC1) {
            qDebug() << "Output image is empty or not in expected format after CUDA processing.";
            return false;
        }

        // 원본 이미지를 그레이스케일 이미지로 업데이트
        image = output.clone(); // 변환된 그레이스케일 이미지로 업데이트
        lastProcessedImage = image.clone(); // 마지막 처리된 이미지 업데이트

        return true;
    }
    catch (const cv::Exception& e) {
        qDebug() << "Exception occurred while converting to grayscale using CUDA:" << e.what();
        return false;
    }
}*/

ImageProcessor::ProcessingResult ImageProcessor::grayScaleOpenCV(cv::Mat& image)
{
    ProcessingResult result;
    result.functionName = "grayScale";
    result.processName = "OpenCV";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    cv::Mat grayImage;
    cv::cvtColor(image, grayImage, cv::COLOR_BGR2GRAY);

    // 원본 이미지를 그레이스케일 이미지로 업데이트
    //image = grayImage.clone(); // 변환된 그레이스케일 이미지로 업데이트
    //lastProcessedImage = image.clone(); // 마지막 처리된 이미지 업데이트

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = grayImage.clone();
    result.processingTime = elapsedTimeMs;

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::grayScaleIPP(cv::Mat& image)
{
    ProcessingResult result;
    result.functionName = "grayScale";
    result.processName = "IPP";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    // IPP 사용을 위한 입력 및 출력 배열 설정
    IppiSize roiSize = { image.cols, image.rows };
    int srcStep = image.step;
    int dstStep = image.cols;
    Ipp8u* srcData = image.data;
    Ipp8u* dstData = ippsMalloc_8u(image.rows * image.cols);

    // IPP 그레이스케일 변환 (고정된 계수 사용)
    IppStatus status = ippiRGBToGray_8u_C3C1R(srcData, srcStep, dstData, dstStep, roiSize);

    if (status != ippStsNoErr) {
        std::cerr << "IPP 오류: " << status << std::endl;
        ippsFree(dstData); // 메모리 해제
        return result; // 오류 발생 시 처리 중단
    }

    // 결과를 OpenCV Mat으로 변환
    cv::Mat grayImage(image.rows, image.cols, CV_8UC1, dstData);

    // 원본 이미지를 그레이스케일 이미지로 업데이트
    //image = grayImage.clone(); // 변환된 그레이스케일 이미지로 업데이트
    //lastProcessedImage = image.clone(); // 마지막 처리된 이미지 업데이트

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = grayImage.clone();
    result.processingTime = elapsedTimeMs;

    ippsFree(dstData); // 메모리 해제

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::grayScaleCUDA(cv::Mat& image)
{
    ProcessingResult result;
    result.functionName = "grayScale";
    result.processName = "CUDA";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    // CUDA 장치 설정
    //cv::cuda::setDevice(0);

    // 입력 이미지를 CUDA GpuMat으로 업로드
    cv::cuda::GpuMat d_input;
    d_input.upload(image);

    // CUDA를 사용하여 그레이스케일로 변환
    cv::cuda::GpuMat d_output;
    cv::cuda::cvtColor(d_input, d_output, cv::COLOR_BGR2GRAY);

    // CUDA에서 호스트로 이미지 다운로드
    cv::Mat grayImage;
    d_output.download(grayImage);

    if (grayImage.empty() || grayImage.type() != CV_8UC1) {
        qDebug() << "Output image is empty or not in expected format after CUDA processing.";
        return result;
    }

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = grayImage.clone();
    result.processingTime = elapsedTimeMs;

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::grayScaleCUDAKernel(cv::Mat& image)
{
    ProcessingResult result;
    result.functionName = "grayScale";
    result.processName = "CUDAKernel";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    callGrayScaleImageCUDA(image);

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = image.clone();
    result.processingTime = elapsedTimeMs;

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::zoomInOpenCV(cv::Mat& image, double newWidth, double newHeight)
{
    ProcessingResult result;

    result.functionName = "zoomIn";
    result.processName = "OpenCV";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    cv::Mat zoomInImage;
    cv::resize(image, zoomInImage, cv::Size(newWidth, newHeight), 0, 0, cv::INTER_LINEAR);

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = zoomInImage;
    result.processingTime = elapsedTimeMs;

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::zoomInIPP(cv::Mat& image, double newWidth, double newHeight) {
    ProcessingResult result;
    result.functionName = "zoomIn";
    result.processName = "IPP";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    cv::Mat zoomedImage;
    zoomedImage.create(static_cast<int>(newHeight), static_cast<int>(newWidth), image.type());

    Ipp8u* pSrcData = reinterpret_cast<Ipp8u*>(image.data);
    Ipp8u* pDstData = reinterpret_cast<Ipp8u*>(zoomedImage.data);

    IppiSize srcSize = { image.cols, image.rows };
    IppiSize dstSize = { static_cast<int>(newWidth), static_cast<int>(newHeight) };
    IppiPoint dstOffset = { 0, 0 };

    int specSize = 0;
    int initSize = 0;
    int bufSize = 0;
    std::vector<Ipp8u> pBuffer;
    IppiResizeSpec_32f* pSpec = nullptr;

    // Get the sizes of the spec and initialization buffers
    IppStatus status = ippiResizeGetSize_8u(srcSize, dstSize, ippNearest, 0, &specSize, &initSize);
    if (status != ippStsNoErr) {
        std::cerr << "Error: ippiResizeGetSize_8u failed with status code " << status << std::endl;
        return result;
    }

    // Allocate the spec and initialization buffers
    pSpec = (IppiResizeSpec_32f*)(ippMalloc(specSize));
    if (!pSpec) {
        std::cerr << "Error: Memory allocation failed for pSpec" << std::endl;
        return result;
    }

    pBuffer.resize(initSize);
    if (pBuffer.empty()) {
        std::cerr << "Error: Memory allocation failed for pBuffer" << std::endl;
        ippFree(pSpec);
        return result;
    }

    // Initialize the resize specification
    status = ippiResizeNearestInit_8u(srcSize, dstSize, pSpec);
    if (status != ippStsNoErr) {
        std::cerr << "Error: ippiResizeNearestInit_8u failed with status code " << status << std::endl;
        ippFree(pSpec);
        return result;
    }

    // Get the size of the working buffer
    status = ippiResizeGetBufferSize_8u(pSpec, dstSize, 3, &bufSize);
    if (status != ippStsNoErr) {
        std::cerr << "Error: ippiResizeGetBufferSize_8u failed with status code " << status << std::endl;
        ippFree(pSpec);
        return result;
    }

    pBuffer.resize(bufSize);
    if (pBuffer.empty()) {
        std::cerr << "Error: Memory allocation failed for pBuffer" << std::endl;
        ippFree(pSpec);
        return result;
    }

    // Perform the resize operation
    status = ippiResizeNearest_8u_C3R(pSrcData, image.step[0], pDstData, zoomedImage.step[0], dstOffset, dstSize, pSpec, pBuffer.data());
    if (status != ippStsNoErr) {
        std::cerr << "Error: ippiResizeNearest_8u_C3R failed with status code " << status << std::endl;
        ippFree(pSpec);
        return result;
    }

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = zoomedImage.clone(); // 처리된 이미지 복사
    result.processingTime = elapsedTimeMs; // 처리 시간 설정

    // 메모리 해제
    ippFree(pSpec);

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::zoomInCUDA(cv::Mat& image, double newWidth, double newHeight)
{
    ProcessingResult result;
    result.functionName = "zoomIn";
    result.processName = "CUDA";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    // GPU 메모리로 이미지 업로드
    cv::cuda::GpuMat d_image;
    d_image.upload(image);

    // 결과 이미지를 저장할 GPU 메모리 할당
    cv::cuda::GpuMat d_zoomInImage;

    // 이미지 크기 조정
    cv::cuda::resize(d_image, d_zoomInImage, cv::Size(static_cast<int>(newWidth), static_cast<int>(newHeight)), 0, 0, cv::INTER_LINEAR);

    // CPU 메모리로 결과 이미지 다운로드
    cv::Mat zoomedImage;
    d_zoomInImage.download(zoomedImage);

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = zoomedImage.clone(); // 처리된 이미지 복사
    result.processingTime = elapsedTimeMs; // 처리 시간 설정

    return result;
}

ImageProcessor::ProcessingResult ImageProcessor::zoomInCUDAKernel(cv::Mat& image, double newWidth, double newHeight)
{
    ProcessingResult result;
    result.functionName = "zoomIn";
    result.processName = "CUDAKernel";

    double startTime = cv::getTickCount(); // 시작 시간 측정

    callResizeImageCUDA(image, newWidth, newHeight);

    double endTime = cv::getTickCount(); // 종료 시간 측정
    double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

    result.processedImage = image.clone(); // 처리된 이미지 복사
    result.processingTime = elapsedTimeMs; // 처리 시간 설정

    return result;
}

double ImageProcessor::getCurrentTimeMs()
{
    return std::chrono::duration_cast<std::chrono::milliseconds>
        (std::chrono::steady_clock::now().time_since_epoch()).count();
}

QFuture<bool> ImageProcessor::gaussianBlur(cv::Mat& image, int kernelSize)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, kernelSize, functionName]() -> bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            if (kernelSize % 2 == 0 || kernelSize < 1) {
                qDebug() << "Invalid kernel size for Gaussian blur.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            // Upload image to GPU
            //cv::cuda::GpuMat gpuImage;
            //gpuImage.upload(image);

            // Create Gaussian filter
            //cv::Ptr<cv::cuda::Filter> gaussianFilter =
            //    cv::cuda::createGaussianFilter(
            //        gpuImage.type(),
            //        gpuImage.type(),
            //        cv::Size(kernelSize, kernelSize),
            //        0);

            // Apply Gaussian blur on GPU
            //cv::cuda::GpuMat blurredGpuImage;
            //gaussianFilter->apply(gpuImage, blurredGpuImage);

            // Download the result back to CPU
            //cv::Mat blurredImage;
            //blurredGpuImage.download(blurredImage);

            //CUDA Kernel
            callGaussianBlurCUDA(image, kernelSize);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //image = blurredImage.clone();
            //lastProcessedImage = image.clone();

            //emit imageProcessed(image, processingTime, functionName);

            return true;

            /* OpenCV
            cv::Mat blurredImage;
            cv::GaussianBlur(image, blurredImage, cv::Size(kernelSize, kernelSize), 0, 0);

            image = blurredImage.clone();
            lastProcessedImage = image.clone();

            emit imageProcessed(image);

            return true;
            */
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while applying Gaussian blur:"
                << e.what();
            return false;
        }
        });
}

//Canny
QFuture<bool> ImageProcessor::cannyEdges(cv::Mat& image)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]() -> bool {
        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            //그레이스케일이 아닌경우
            if (image.channels() != 1)
            {
                //if (!grayScaleCUDA(image)) {
                //    return false;
                //}

                //CUDA Kernel
                callGrayScaleImageCUDA(image);
            }

            // GPU에서 캐니 엣지 감지기 생성
            //cv::cuda::GpuMat d_input(image);
            //cv::cuda::GpuMat d_cannyEdges;
            //cv::Ptr<cv::cuda::CannyEdgeDetector> cannyDetector = cv::cuda::createCannyEdgeDetector(50, 150);
            //cannyDetector->detect(d_input, d_cannyEdges);

            // 결과를 CPU 메모리로 복사
            //cv::Mat edges;
            //d_cannyEdges.download(edges);

            // 출력 이미지에 초록색 엣지 표시
            //cv::Mat outputImage = cv::Mat::zeros(image.size(), CV_8UC3); // 3-channel BGR image
            //cv::Mat mask(edges.size(), CV_8UC1, cv::Scalar(0)); // Mask for green edges
            //mask.setTo(cv::Scalar(255), edges); // Set pixels to 255 (white) where edges are detected
            //cv::Mat channels[3];
            //cv::split(outputImage, channels);
            //channels[1] = mask; // Green channel is set by mask
            //cv::merge(channels, 3, outputImage); // Merge channels to get green edges

            //CUDA Kernel
            callCannyEdgesCUDA(image);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //image = outputImage.clone();
            //lastProcessedImage = image.clone();

            // GPU 메모리 해제
            //d_cannyEdges.release();

            //emit imageProcessed(image, processingTime, functionName);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while applying Canny edges:" << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::medianFilter(cv::Mat& image)
{

    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]()->bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "median 필터를 적용할 이미지가 없습니다.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            // Upload image to GPU
            //cv::cuda::GpuMat gpuImage;
            //gpuImage.upload(image);

            // Create median filter
            //cv::Ptr<cv::cuda::Filter> medianFilter =
            //    cv::cuda::createMedianFilter(gpuImage.type(), 5);

            // Apply median filter on GPU
            //cv::cuda::GpuMat medianedGpuImage;
            //medianFilter->apply(gpuImage, medianedGpuImage);

            // Download the result back to CPU
            //cv::Mat medianedImage;
            //medianedGpuImage.download(medianedImage);

            //CUDA Kernel
            callMedianFilterCUDA(image);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //image = medianedImage.clone();
            //lastProcessedImage = image.clone();

            //emit imageProcessed(image, processingTime, functionName);

            return true;

            /*
            cv::Mat medianedImage;
            cv::medianBlur(image, medianedImage, 5);
            image = medianedImage.clone();
            lastProcessedImage = image.clone();

            emit imageProcessed(image);

            return true;
            */
        }
        catch (const cv::Exception& e) {
            qDebug() << "median 필터 적용 중 오류 발생: "
                << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::laplacianFilter(cv::Mat& image)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]()->bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "laplacian 필터를 적용할 이미지가 없습니다.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            //cv::Mat filteredImage;
            //cv::Laplacian(image, filteredImage, CV_8U, 3);

            //CUDA Kernel
            callLaplacianFilterCUDA(image);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //image = filteredImage.clone();
            //lastProcessedImage = image.clone();

            //emit imageProcessed(image, processingTime, functionName);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "laplacian 필터 적용 중 오류 발생: "
                << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::bilateralFilter(cv::Mat& image)
{
    //함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]()->bool {

        QMutexLocker locker(&mutex);

        try {

            if (image.empty()) {
                qDebug() << "bilateral 필터를 적용할 이미지가 없습니다.";
                return false;
            }

            //pushToUndoStack(image);

            // 처리시간계산 시작
            double startTime = getCurrentTimeMs();

            //CUDA Kernel
            callBilateralFilterCUDA(image, 9, 75, 75);

            //cv::Mat filteredImage;
            //cv::bilateralFilter(image, filteredImage, 9, 75, 75);

            // 처리시간계산 종료
            double endTime = getCurrentTimeMs();
            double processingTime = endTime - startTime;

            //image = filteredImage.clone();
            //lastProcessedImage = image.clone();

            //emit imageProcessed(image, processingTime, functionName);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "bilateral 필터 적용 중 오류 발생: "
                << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::sobelFilter(cv::Mat& image)
{
    // 함수 이름을 문자열로 저장
    const char* functionName = __func__;

    return QtConcurrent::run([this, &image, functionName]()->bool {
        if (cv::cuda::getCudaEnabledDeviceCount() <= 0) {
            qDebug() << "No CUDA-enabled device found. Falling back to CPU implementation.";
            return false;
        }

        //pushToUndoStack(image);

        // 처리시간계산 시작
        double startTime = getCurrentTimeMs();

        //cv::cuda::GpuMat gpuImage, gpuGray, gpuSobelX, gpuSobelY;

        // 입력 이미지가 BGR 색상 포맷이 아닌 경우, BGR2GRAY 변환 수행
        //if (image.channels() != 3) {
        //    qDebug() << "Input image is not in BGR format. Converting to BGR...";
        //    cv::cvtColor(image, image, cv::COLOR_GRAY2BGR); // 예시로 GRAY2BGR 사용. 실제로는 적절한 변환 사용
        //}

        //gpuImage.upload(image);
        //cv::cuda::cvtColor(gpuImage, gpuGray, cv::COLOR_BGR2GRAY);

        //cv::Ptr<cv::cuda::Filter> sobelX =
        //    cv::cuda::createSobelFilter(gpuGray.type(), CV_16S, 1, 0);
        //cv::Ptr<cv::cuda::Filter> sobelY =
        //    cv::cuda::createSobelFilter(gpuGray.type(), CV_16S, 0, 1);

        //sobelX->apply(gpuGray, gpuSobelX);
        //sobelY->apply(gpuGray, gpuSobelY);

        //cv::cuda::GpuMat sobelX_8U, sobelY_8U;
        //gpuSobelX.convertTo(sobelX_8U, CV_8U);
        //gpuSobelY.convertTo(sobelY_8U, CV_8U);

        //cv::cuda::addWeighted(sobelX_8U, 0.5, sobelY_8U, 0.5, 0, gpuGray);

        //cv::Mat sobeledImage;
        //gpuGray.download(sobeledImage);

        //CUDA Kernel
        callSobelFilterCUDA(image);

        // 처리시간계산 종료
        double endTime = getCurrentTimeMs();
        double processingTime = endTime - startTime;

        //image = sobeledImage.clone();
        //lastProcessedImage = image.clone();

        //emit imageProcessed(image, processingTime, functionName);

        return true;
        });
}


bool ImageProcessor::canUndoOpenCV() const
{
    return !undoStackOpenCV.empty();
}

bool ImageProcessor::canRedoOpenCV() const
{
    return !redoStackOpenCV.empty();
}

//실행취소
// Undo operation
void ImageProcessor::undo()
{
    const char* functionName = __func__;
    QVector<ProcessingResult> results;

    try {
        if (!canUndoOpenCV()) {
            throw std::runtime_error("Cannot undo: Undo stack is empty");
        }

        double startTime = cv::getTickCount(); // 시작 시간 측정        

        // 현재 이미지를 redo 스택에 푸시
        redoStackOpenCV.push(lastProcessedImageOpenCV.clone());
        redoStackIPP.push(lastProcessedImageIPP.clone());
        redoStackCUDA.push(lastProcessedImageCUDA.clone());
        redoStackCUDAKernel.push(lastProcessedImageCUDAKernel.clone());

        // undo 스택에서 이미지 복원
        lastProcessedImageOpenCV = undoStackOpenCV.top().clone();
        lastProcessedImageIPP = undoStackIPP.top().clone();
        lastProcessedImageCUDA = undoStackCUDA.top().clone();
        lastProcessedImageCUDAKernel = undoStackCUDAKernel.top().clone();

        // undo 스택에서 이미지 제거
        undoStackOpenCV.pop();
        undoStackIPP.pop();
        undoStackCUDA.pop();
        undoStackCUDAKernel.pop();

        double endTime = cv::getTickCount(); // 종료 시간 측정
        double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

        // 결과 생성
        results.append(ProcessingResult(functionName, "OpenCV", lastProcessedImageOpenCV.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "IPP", lastProcessedImageIPP.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "CUDA", lastProcessedImageCUDA.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "CUDAKernel", lastProcessedImageCUDAKernel.clone(), elapsedTimeMs));

        emit imageProcessed(results);
    }
    catch (const std::exception& e) {
        qDebug() << "Exception occurred in ImageProcessor::undo(): " << e.what();
    }
}


//재실행
void ImageProcessor::redo()
{
    const char* functionName = __func__;
    QVector<ProcessingResult> results;

    try {
        if (!canRedoOpenCV()) {
            throw std::runtime_error("Cannot redo: Redo stack is empty");
        }

        double startTime = cv::getTickCount(); // 시작 시간 측정        

        // 현재 이미지를 undo 스택에 푸시
        undoStackOpenCV.push(lastProcessedImageOpenCV.clone());
        undoStackIPP.push(lastProcessedImageIPP.clone());
        undoStackCUDA.push(lastProcessedImageCUDA.clone());
        undoStackCUDAKernel.push(lastProcessedImageCUDAKernel.clone());

        // redo 스택에서 이미지 복원
        lastProcessedImageOpenCV = redoStackOpenCV.top().clone();
        lastProcessedImageIPP = redoStackIPP.top().clone();
        lastProcessedImageCUDA = redoStackCUDA.top().clone();
        lastProcessedImageCUDAKernel = redoStackCUDAKernel.top().clone();

        // redo 스택에서 이미지 제거
        redoStackOpenCV.pop();
        redoStackIPP.pop();
        redoStackCUDA.pop();
        redoStackCUDAKernel.pop();

        double endTime = cv::getTickCount(); // 종료 시간 측정
        double elapsedTimeMs = (endTime - startTime) / cv::getTickFrequency() * 1000.0; // 시간 계산

        // 결과 생성
        results.append(ProcessingResult(functionName, "OpenCV", lastProcessedImageOpenCV.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "IPP", lastProcessedImageIPP.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "CUDA", lastProcessedImageCUDA.clone(), elapsedTimeMs));
        results.append(ProcessingResult(functionName, "CUDAKernel", lastProcessedImageCUDAKernel.clone(), elapsedTimeMs));

        emit imageProcessed(results);
    }
    catch (const std::exception& e) {
        qDebug() << "Exception occurred in ImageProcessor::redo(): " << e.what();
    }
}



void ImageProcessor::cleanUndoStack()
{
    QMutexLocker locker(&mutex);
    while (!undoStackOpenCV.empty()) {
        undoStackOpenCV.pop();
    }

    while (!undoStackIPP.empty()) {
        undoStackIPP.pop();
    }

    while (!undoStackCUDA.empty()) {
        undoStackCUDA.pop();
    }

    while (!undoStackCUDAKernel.empty()) {
        undoStackCUDAKernel.pop();
    }
}

void ImageProcessor::cleanRedoStack()
{
    QMutexLocker locker(&mutex);
    while (!redoStackOpenCV.empty()) {
        redoStackOpenCV.pop();
    }

    while (!redoStackIPP.empty()) {
        redoStackIPP.pop();
    }

    while (!redoStackCUDA.empty()) {
        redoStackCUDA.pop();
    }

    while (!redoStackCUDAKernel.empty()) {
        redoStackCUDAKernel.pop();
    }
}

void ImageProcessor::initializeCUDA()
{
    // 임의의 작은 작업을 수행하여 CUDA 초기화를 유도
    cv::cuda::GpuMat temp;
    temp.upload(cv::Mat::zeros(1, 1, CV_8UC1));
    cv::cuda::cvtColor(temp, temp, cv::COLOR_GRAY2BGR);
}

const cv::Mat& ImageProcessor::getLastProcessedImageOpenCV() const
{
    return lastProcessedImageOpenCV;
}

const cv::Mat& ImageProcessor::getLastProcessedImageIPP() const
{
    return lastProcessedImageIPP;
}

const cv::Mat& ImageProcessor::getLastProcessedImageCUDA() const
{
    return lastProcessedImageCUDA;
}

const cv::Mat& ImageProcessor::getLastProcessedImageCUDAKernel() const
{
    return lastProcessedImageCUDAKernel;
}

void ImageProcessor::pushToUndoStackOpenCV(const cv::Mat& image)
{
    undoStackOpenCV.push(image.clone());
}

void ImageProcessor::pushToUndoStackIPP(const cv::Mat& image)
{
    undoStackIPP.push(image.clone());
}

void ImageProcessor::pushToUndoStackCUDA(const cv::Mat& image)
{
    undoStackCUDA.push(image.clone());
}

void ImageProcessor::pushToUndoStackCUDAKernel(const cv::Mat& image)
{
    undoStackCUDAKernel.push(image.clone());
}

void ImageProcessor::pushToRedoStackOpenCV(const cv::Mat& image)
{
    redoStackOpenCV.push(image.clone());
}

void ImageProcessor::pushToRedoStackIPP(const cv::Mat& image)
{
    redoStackIPP.push(image.clone());
}

void ImageProcessor::pushToRedoStackCUDA(const cv::Mat& image)
{
    redoStackCUDA.push(image.clone());
}

void ImageProcessor::pushToRedoStackCUDAKernel(const cv::Mat& image)
{
    redoStackCUDAKernel.push(image.clone());
}

5. CMakeLists.txt
cmake_minimum_required(VERSION 3.14)
project(Project1 LANGUAGES CXX CUDA)

# Qt, OpenCV, CUDA 설정
set(CMAKE_PREFIX_PATH "C:/Qt/6.7.1/msvc2019_64" "C:/opencv/build")
find_package(Qt6 REQUIRED COMPONENTS Widgets Core Gui)
find_package(OpenCV REQUIRED COMPONENTS core imgproc highgui cudaarithm cudafilters cudawarping cudacodec cudafeatures2d cudaimgproc)
find_package(CUDA REQUIRED)

# IPP 설정
set(IPP_ROOT "C:/Program Files (x86)/Intel/oneAPI/ipp/2021.11")  # IPP 라이브러리 설치 경로
include_directories("${IPP_ROOT}/include")
link_directories("${IPP_ROOT}/lib")  # IPP 라이브러리 lib 경로

# 추가 포함 디렉터리 설정
include_directories(
    ${CUDA_INCLUDE_DIRS}
    ${OpenCV_INCLUDE_DIRS}
    ${IPP_ROOT}/include
)

# CUDA 파일 설정
set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} -std=c++14 --expt-relaxed-constexpr -gencode arch=compute_86,code=sm_86)

# Qt 래핑 파일 생성
qt6_wrap_cpp(MOC_FILES
    MainWindow.h
    ImageProcessor.h
)

# CUDA 파일 컴파일 및 라이브러리 생성
cuda_add_library(image_processing
    imageProcessing.cu
)

# IPP 라이브러리 링크
target_link_libraries(image_processing
    ippcc.lib
    ippcore.lib
    ippvm.lib
    ipps.lib
    ippi.lib
)

# 실행 파일 추가
add_executable(Project1
    main.cpp
    MainWindow.cpp
    MainWindow.h
    MainWindow.ui
    ImageProcessor.cpp
    ImageProcessor.h
    ${MOC_FILES}
)

# 라이브러리 링크
target_link_libraries(Project1
    Qt6::Widgets
    Qt6::Core
    Qt6::Gui
    ${OpenCV_LIBS}
    image_processing
    ${CUDA_LIBRARIES}
    ${CUDNN_LIBRARIES}
)

# 실행 파일 출력 디렉토리 설정
set_target_properties(Project1 PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY_DEBUG "${CMAKE_BINARY_DIR}/Debug"
    RUNTIME_OUTPUT_DIRECTORY_RELEASE "${CMAKE_BINARY_DIR}/Release"
)

# 디버그 빌드에서의 OpenCV opencv_world DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/x64/vc16/bin/opencv_world4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Debug opencv_world DLL to output directory"
)

# 릴리스 빌드에서의 OpenCV opencv_world DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/x64/vc16/bin/opencv_world4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Release opencv_world DLL to output directory"
)

# 디버그 빌드에서의 OpenCV DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudaarithm4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudaimgproc4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_cudafilters4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_imgcodecs4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_core4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Debug/opencv_imgproc4100d.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Debug DLLs to output directory"
)

# 릴리스 빌드에서의 OpenCV DLL 복사
add_custom_command(TARGET Project1 POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudaarithm4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudaimgproc4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_cudafilters4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_imgcodecs4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_core4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
    "C:/opencv/build/bin/Release/opencv_imgproc4100.dll" "$<TARGET_FILE_DIR:Project1>"
    COMMENT "Copying OpenCV Release DLLs to output directory"
)

# 파일 인코딩 설정 추가
add_compile_options("$<$<CXX_COMPILER_ID:MSVC>:/utf-8>")

if (MSVC)
    set_property(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} PROPERTY VS_STARTUP_PROJECT Project1)

    # Debug 빌드
    set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG} /MDd")
    set(CMAKE_C_FLAGS_DEBUG "${CMAKE_C_FLAGS_DEBUG} /MDd")

    # Release 빌드
    set(CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE} /MD")
    set(CMAKE_C_FLAGS_RELEASE "${CMAKE_C_FLAGS_RELEASE} /MD")

    # 반복자 디버그 레벨 설정
    add_compile_definitions(
        $<$<CONFIG:Debug>:_ITERATOR_DEBUG_LEVEL=2>
        $<$<CONFIG:Release>:_ITERATOR_DEBUG_LEVEL=0>
    )
endif()

6.MainWindow.ui
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>MainWindow</class>
 <widget class="QMainWindow" name="MainWindow">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>800</width>
    <height>600</height>
   </rect>
  </property>
  <widget class="QWidget" name="centralwidget">
   <layout class="QVBoxLayout" name="verticalLayout">
    <item>
     <layout class="QVBoxLayout" name="verticalLayout_images_and_times">
      <item>
       <layout class="QHBoxLayout" name="horizontalLayout_row1">
        <item>
         <widget class="QLabel" name="label_opencv">
          <property name="text">
           <string>label_opencv</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignCenter</set>
          </property>
           <property name="scaledContents">
           <bool>true</bool>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QLabel" name="label_ipp">
          <property name="text">
           <string>label_ipp</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignCenter</set>
          </property>
          
          <property name="scaledContents">
           <bool>true</bool>
          </property>
         </widget>
        </item>
       </layout>
      </item>
      <item>
       <layout class="QHBoxLayout" name="horizontalLayout_row2">
        <item>
         <widget class="QLabel" name="label_opencv_title">
          <property name="text">
           <string>Processing Time:</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignLeft</set>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QLabel" name="label_ipp_title">
          <property name="text">
           <string>Processing Time:</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignLeft</set>
          </property>
         </widget>
        </item>
       </layout>
      </item>
      <item>
       <layout class="QHBoxLayout" name="horizontalLayout_row3">
        <item>
         <widget class="QLabel" name="label_cuda">
          <property name="text">
           <string>label_cuda</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignCenter</set>
          </property>
          
          <property name="scaledContents">
           <bool>true</bool>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QLabel" name="label_cudakernel">
          <property name="text">
           <string>label_cudakernel</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignCenter</set>
          </property>
          
          
          <property name="scaledContents">
           <bool>true</bool>
          </property>
         </widget>
        </item>
       </layout>
      </item>
      <item>
       <layout class="QHBoxLayout" name="horizontalLayout_row4">
        <item>
         <widget class="QLabel" name="label_cuda_title">
          <property name="text">
           <string>Processing Time:</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignLeft</set>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QLabel" name="label_cudakernel_title">
          <property name="text">
           <string>Processing Time:</string>
          </property>
          <property name="alignment">
           <set>Qt::AlignLeft</set>
          </property>
         </widget>
        </item>
       </layout>
      </item>
     </layout>
    </item>
   </layout>
  </widget>
  <widget class="QMenuBar" name="menubar">
   <property name="geometry">
    <rect>
     <x>0</x>
     <y>0</y>
     <width>800</width>
     <height>26</height>
    </rect>
   </property>
   <widget class="QMenu" name="menuFile">
    <property name="title">
     <string>File</string>
    </property>
    <addaction name="actionOpen"/>
    <addaction name="actionSave"/>
    <addaction name="actionExit"/>
   </widget>
   <widget class="QMenu" name="menuEdit">
    <property name="title">
     <string>Edit</string>
    </property>
    <addaction name="actionRotate"/>
    <addaction name="actionZoomIn"/>
    <addaction name="actionZoomOut"/>
    <addaction name="actionUndo"/> <!-- Undo 앞에 추가 -->
    <addaction name="actionRedo"/> <!-- Redo 앞에 추가 -->
    <addaction name="actionFirst"/> <!-- 처음 추가 -->
   </widget>
   <widget class="QMenu" name="menuFilters">
    <property name="title">
     <string>Filters</string>
    </property>
    <addaction name="actionGrayscale"/>
    <addaction name="actionGaussianBlur"/>
    <addaction name="actionCannyEdges"/>
    <addaction name="actionMedianFilter"/> <!-- Median Filter 추가 -->
    <addaction name="actionSobelFilter"/> <!-- Sobel Filter 추가 -->
    <addaction name="actionLaplacianFilter"/> <!-- Laplacian Filter 추가 -->
    <addaction name="actionBilateralFilter"/> <!-- Bilateral Filter 추가 -->
   </widget>
   <addaction name="menuFile"/>
   <addaction name="menuEdit"/>
   <addaction name="menuFilters"/>
  </widget>
  <widget class="QStatusBar" name="statusbar"/>
  <widget class="QToolBar" name="fileToolBar">
   <attribute name="toolBarArea">
    <enum>TopToolBarArea</enum>
   </attribute>
   <attribute name="toolBarBreak">
    <bool>false</bool>
   </attribute>
   <addaction name="actionOpen"/>
   <addaction name="actionSave"/>
   <addaction name="actionExit"/>
  </widget>
  <widget class="QToolBar" name="filtersToolBar">
   <attribute name="toolBarArea">
    <enum>TopToolBarArea</enum>
   </attribute>
   <attribute name="toolBarBreak">
    <bool>false</bool>
   </attribute>
   <addaction name="actionGrayscale"/>
   <addaction name="actionGaussianBlur"/>
   <addaction name="actionCannyEdges"/>
   <addaction name="actionMedianFilter"/> <!-- Median Filter 추가 -->
   <addaction name="actionSobelFilter"/> <!-- Sobel Filter 추가 -->
   <addaction name="actionLaplacianFilter"/> <!-- Laplacian Filter 추가 -->
   <addaction name="actionBilateralFilter"/> <!-- Bilateral Filter 추가 -->
  </widget>
  <widget class="QToolBar" name="mainToolBar">
   <attribute name="toolBarArea">
    <enum>TopToolBarArea</enum>
   </attribute>
   <attribute name="toolBarBreak">
    <bool>false</bool>
   </attribute>
   <addaction name="actionRotate"/>
   <addaction name="actionZoomIn"/>
   <addaction name="actionZoomOut"/>
   <addaction name="actionUndo"/> <!-- Undo 액션 추가 -->
   <addaction name="actionRedo"/> <!-- Redo 액션 추가 -->
   <addaction name="actionFirst"/> <!-- 처음 추가 -->
  </widget>
  <action name="actionOpen">
   <property name="text">
    <string>&amp;Open</string>
   </property>
  </action>
  <action name="actionSave">
   <property name="text">
    <string>&amp;Save</string>
   </property>
  </action>
  <action name="actionExit">
   <property name="text">
    <string>E&amp;xit</string>
   </property>
  </action>
  <action name="actionRotate">
   <property name="text">
    <string>&amp;Rotate</string>
   </property>
  </action>
  <action name="actionZoomIn">
   <property name="text">
    <string>Zoom &amp;In</string>
   </property>
  </action>
  <action name="actionZoomOut">
   <property name="text">
    <string>Zoom &amp;Out</string>
   </property>
  </action>
  <action name="actionUndo">
   <property name="text">
    <string>&amp;Undo</string>
   </property>
  </action>
  <action name="actionRedo">
   <property name="text">
    <string>&amp;Redo</string>
   </property>
  </action>
  <action name="actionFirst">
   <property name="text">
    <string>&amp;First</string>
   </property>
  </action>
  <action name="actionGrayscale">
   <property name="text">
    <string>&amp;Grayscale</string>
   </property>
  </action>
  <action name="actionGaussianBlur">
   <property name="text">
    <string>&amp;Gaussian Blur</string>
   </property>
  </action>
  <action name="actionCannyEdges">
   <property name="text">
    <string>&amp;Canny Edges</string>
   </property>
  </action>
  <action name="actionMedianFilter">
   <property name="text">
    <string>&amp;Median Filter</string>
   </property>
  </action>
  <action name="actionSobelFilter">
   <property name="text">
    <string>&amp;Sobel Filter</string>
   </property>
  </action>
  <action name="actionLaplacianFilter">
   <property name="text">
    <string>&amp;Laplacian Filter</string>
   </property>
  </action>
  <action name="actionBilateralFilter">
   <property name="text">
    <string>&amp;Bilateral Filter</string>
   </property>
  </action>
 </widget>
 <layoutdefault spacing="6" margin="11"/>
 <resources/>
 <connections/>
</ui>
