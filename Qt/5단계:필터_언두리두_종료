<그레이스케일/가우시안블러/케니엣지검출,언두/리두,종료기능추가>

1.ImageProcessor.h

1) 객체 지향 설계
ImageProessor클래스를 사용하여 이미지 처리 기능을 캡슐화하고, 관련된 데이터와 메섣를
한 곳에 모아 관리한다.
2)Qt통합
QtObject를 상속받아 Qt의 신호와 슬롯 메커니즘을 사용할 수 있고 UI와의 통신을 
쉽게 할 수 있다.
3)스레드안전
QMutex와 QMutexLocker를 사용하여 멀티스레드 환경에서의 데이터 접근을 안전하게 보호
4)비동기작업
QtConcurrent::run을 사용하여 이미지 처리 작업을 비동기로 수행.
UI의 응답성을 유지할 수 있다.
5)실행 취소 및 재실행
undoStack과 redoStack을 사용하여 실행 취소 및 재실행 기능 제공. 이를 통해 사용자는
실수나 변경 사항을 쉽게 되돌릴 수 있다.

//ImageProcessor.h
//ImageProcessor.h
#ifndef IMAGEPROCESSOR_H
#define IMAGEPROCESSOR_H

#include <stack>
#include <QObject>
#include <QDebug>
#include <QMutex>
#include <QMutexLocker>
#include <QtConcurrent/QtConcurrent>
#include <opencv2/core.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc.hpp>
//#include <ipp.h>
//#include <ipp/ippi.h>
//#include <ipp/ippcc.h>
//#include <opencv2/cuda>

class ImageProcessor : public QObject
{
    Q_OBJECT

public:
    explicit ImageProcessor(QObject* parent = nullptr);
    ~ImageProcessor();

    bool openImage(const std::string& fileName, cv::Mat& image);
    bool saveImage(const std::string& fileName, const cv::Mat& image);
    QFuture<bool> rotateImage(cv::Mat& image);
    QFuture<bool> zoomImage(cv::Mat& image, double scaleFactor);
    QFuture<bool> convertToGrayscaleAsync(cv::Mat& image);
    QFuture<bool> applyGaussianBlur(cv::Mat& image, int kernelSize);
    QFuture<bool> detectEdges(cv::Mat& image);

    bool canUndo() const;
    bool canRedo() const;
    void undo();
    void redo();

    const cv::Mat& getLastProcessedImage() const;

signals: //이벤트 발생을 알림
    void imageProcessed(const cv::Mat& processedImage);

//slots: //이벤트를 처리하는 함수 지칭

private: 
    cv::Mat lastProcessedImage;
    QMutex mutex;
    std::stack<cv::Mat> undoStack;
    std::stack<cv::Mat> redoStack;

    void pushToUndoStack(const cv::Mat& image);
    void pushToRedoStack(const cv::Mat& image);

    cv::Mat converToGrayScale(const cv::Mat& image);
};

#endif // IMAGEPROCESSOR_H

2.ImageProcessor.cpp
//ImageProcessor.cpp
#include "ImageProcessor.h"

ImageProcessor::ImageProcessor(QObject* parent) : QObject(parent)
{
}

ImageProcessor::~ImageProcessor()
{
}

bool ImageProcessor::openImage(const std::string& fileName, cv::Mat& image)
{
    image = cv::imread(fileName);
    if (image.empty()) {
        qDebug() << "Failed to open image: " << QString::fromStdString(fileName);
        return false;
    }
    return true;
}

bool ImageProcessor::saveImage(const std::string& fileName, const cv::Mat& image)
{
    if (!cv::imwrite(fileName, image)) {
        qDebug() << "Failed to save image: " << QString::fromStdString(fileName);
        return false;
    }
    return true;
}

//이미지를 90도 회전시키는 비동기 작업 수행
QFuture<bool> ImageProcessor::rotateImage(cv::Mat& image) {

    return QtConcurrent::run([this, &image]()->bool {

        //여러 스레드가 동시에 image 객체에 접근하지 못하게 함
        QMutexLocker locker(&mutex);

        //작업시작전에 원본 이미지를 실행 취소 스택에 저장
        pushToUndoStack(image);

        try {

            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //OpenCV로 이미지 회전
            cv::Mat rotatedImage;
            cv::rotate(image, rotatedImage, cv::ROTATE_90_CLOCKWISE);

            //회전된 이미지를 저장
            image = rotatedImage.clone();
            lastProcessedImage = image.clone();

            //시그널 발생
            emit imageProcessed(image);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occured while rotating image:"
                << e.what();
            return false;
        }
        
    });

}

//이미지를 지정된 배율로 확대 축소하는 비동기 작업 수행
QFuture<bool> ImageProcessor::zoomImage(cv::Mat& image, double scaleFactor)
{    
    //QtConcurrent::run을 사용하여 비동기 작업을 시작하고,
    //작업결과를 QFuture<bool>로 반환
    return QtConcurrent::run([this, &image, scaleFactor]() -> bool {
        
        QMutexLocker locker(&mutex);

        pushToUndoStack(image);
        
        try {
            
            if (image.empty()) {
                qDebug() << "입력 이미지가 비어 있습니다.";
                return false;
            }

            if (scaleFactor <= 0) {
                qDebug() << "잘못된 확대/축소 배율입니다.";
                return false;
            }            

            //새로운 이미지 크기 계산
            int newWidth = static_cast<int>(image.cols * scaleFactor);
            int newHeight = static_cast<int>(image.rows * scaleFactor);

            //이미지를 새로운 크기로 리사이즈한다.
            cv::Mat zoomedImage;
            //cv::INTER_LINEAR : 새 픽셀 위치에 가장 가까운 4개의 원본 픽셀을 찾아
            //각 픽셀의 거리 가중치를 곱해 평균을 낸다.
            //0,0 : 가로,세로방향 스케일링 요소, 자동계산
            cv::resize(image, zoomedImage, cv::Size(newWidth, newHeight), 0, 0, cv::INTER_LINEAR);
            
            image = zoomedImage.clone(); // 이미지를 복사하여 업데이트
            lastProcessedImage = image.clone();

            emit imageProcessed(image); // 이미지 처리 완료 시그널 발생

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "이미지 확대/축소 중 예외가 발생했습니다:" << e.what();
            return false;
        }
        });
}

QFuture<bool> ImageProcessor::convertToGrayscale(cv::Mat& image)
{
    return QtConcurrent::run([this, &image]() -> bool {

        QMutexLocker locker(&mutex);

        pushToUndoStack(image);

        try {
            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //이미지의 채널을 저장할 벡터 선언
            std::vector<cv::Mat> channels;
            //이미지를 채널별로 분리, BGR 이미지를 세 개의 채널로 나눈다.
            cv::split(image, channels);

            // 그레이스케일 이미지를 저장할 변수
            cv::Mat gray;
            // 컬러이미지를 그레이스케일로 변환
            cv::cvtColor(image, gray, cv::COLOR_BGR2GRAY);

            // 그레이스케일 이미지를 RGB 형식으로 변환
            cv::Mat merged;
            cv::merge(std::vector<cv::Mat>{gray, gray, gray}, merged);

            // 원본 이미지에 그레이스케일 이미지 적용
            image = merged.clone();
            lastProcessedImage = image.clone();

            emit imageProcessed(image); // 이미지 처리가 완료되었음을 시그널로 알림
            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while converting to grayscale:" << e.what();
            return false;
        }
        });
}


QFuture<bool> ImageProcessor::applyGaussianBlur(cv::Mat& image, int kernelSize)
{
    return QtConcurrent::run([this, &image, kernelSize]() -> bool {
        
        QMutexLocker locker(&mutex);

        pushToUndoStack(image);

        try {
            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //커널 크기 유효성 검사 
            //가우시안 블러의 커널 크기가 홀수인지, 그리고 1 이상인지 검사
            //짝수 크기는 유효하지 않다.
            if (kernelSize % 2 == 0 || kernelSize < 1) {
                qDebug() << "Invalid kernel size for Gaussian blur.";
                return false;
            }

            cv::Mat blurredImage;
            cv::GaussianBlur(image, blurredImage, cv::Size(kernelSize, kernelSize), 0, 0);

            image = blurredImage.clone();
            lastProcessedImage = image.clone();

            emit imageProcessed(image);

            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while applying Gaussian blur:"
                << e.what();
            return false;
        }
    });
}

//Canny edge
//주어진 이미지에서 엣지(가장자리)를 검출하는 비동기 작업을 수행
QFuture<bool> ImageProcessor::detectEdges(cv::Mat& image)
{
    return QtConcurrent::run([this, &image]() -> bool {

        QMutexLocker locker(&mutex);

        pushToUndoStack(image);

        try {
            if (image.empty()) {
                qDebug() << "Input image is empty.";
                return false;
            }

            //회색조이미지
            cv::Mat gray = converToGrayScale(image);

            //엣지 검출
            cv::Mat edges; //엣지감지결과
            //50:하위 임계값(threshold1)
            //엣지후보로 고려되기 위한 최소 강도 
            //임계값보다 낮은 강도의 엣지는 제거된다.
            //150:상위 임계값(threshold2)
            //강한 엣지로 간주되는 임계값
            //두 임계값 사이의 강도를 가진 엣지는 연결되어
            //하나의 엣지로 유지된다
            cv::Canny(gray, edges, 50, 150);

            cv::Mat outputImage;
            gray.copyTo(outputImage); //회색조이미지를 복사
            outputImage.setTo(cv::Scalar(0, 255, 0), edges); // Green edges
            
            image = outputImage.clone();
            lastProcessedImage = image.clone();
            
            emit imageProcessed(image);
            return true;
        }
        catch (const cv::Exception& e) {
            qDebug() << "Exception occurred while detecting edges:" << e.what();
            return false;
        }
        });
}

bool ImageProcessor::canUndo() const
{
    return !undoStack.empty();
}

bool ImageProcessor::canRedo() const
{
    return !redoStack.empty();
}

//실행취소
void ImageProcessor::undo()
{
    try {

        if (!canUndo())
            throw std::runtime_error("Cannot redo: undo stack is empty");

        cv::Mat imageToRestore = undoStack.top();
        redoStack.push(lastProcessedImage);
        lastProcessedImage = imageToRestore.clone();
        undoStack.pop();

        emit imageProcessed(lastProcessedImage);

    }
    catch (const std::exception& e) {
        qDebug() << "Exception occurred in ImageProcessor::undo(): "
            << e.what();
    }
}

//재실행
void ImageProcessor::redo()
{
    try {

        if (!canRedo())
            throw std::runtime_error("Cannot redo: redo stack is empty");

        cv::Mat imageToRestore = redoStack.top();
        undoStack.push(lastProcessedImage);
        lastProcessedImage = imageToRestore.clone();
        redoStack.pop();

        emit imageProcessed(lastProcessedImage);

    }
    catch (const std::exception& e) {
        qDebug() << "Exception occurred in ImageProcessor::redo(): " 
            << e.what();
    }
}

const cv::Mat& ImageProcessor::getLastProcessedImage() const
{
    return lastProcessedImage;
}

void ImageProcessor::pushToUndoStack(const cv::Mat& image)
{
    undoStack.push(image.clone());
}

void ImageProcessor::pushToRedoStack(const cv::Mat& image)
{
    redoStack.push(image.clone());
}

3.MainWndow.h
//MainWindow.h
#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#include <QMainWindow>
#include <QImage>
#include <QPixmap>
#include <QFileDialog>
#include <QMessageBox>
#include <QInputDialog>
#include <opencv2/opencv.hpp>
#include "ImageProcessor.h"
#include "ui_MainWindow.h"

QT_BEGIN_NAMESPACE
namespace Ui { class MainWindow; }
QT_END_NAMESPACE

class MainWindow : public QMainWindow
{
    Q_OBJECT

public:
    MainWindow(QWidget* parent = nullptr);
    ~MainWindow();

private slots:
    void openFile();
    void saveFile();
    void rotateImage();
    void zoomInImage();
    void zoomOutImage();
    void convertToGrayscale();
    void applyGaussianBlur();
    void detectEdges();
    void exitApplication();
    void redoAction();
    void undoAction();
    void displayImage(const cv::Mat& image);

private:
    Ui::MainWindow* ui;
    cv::Mat currentImage;
    ImageProcessor* imageProcessor;
    double scaleFactor;

    
    void connectActions();
    void connectImageProcessor();
    void setInitialWindowGeometry();
};

#endif // MAINWINDOW_H

4.MainWindow.cpp
//MainWindow.cpp
#include "MainWindow.h"

MainWindow::MainWindow(QWidget* parent)
    : QMainWindow(parent)
    , ui(new Ui::MainWindow)
    , imageProcessor(new ImageProcessor)
    , scaleFactor(1.0)
{
    ui->setupUi(this);

    connectActions();

    connectImageProcessor();

    setInitialWindowGeometry();
}

MainWindow::~MainWindow()
{
    delete ui;
    delete imageProcessor;
}

void MainWindow::openFile()
{
    QString fileName = QFileDialog::getOpenFileName(this, tr("Open Image"), "", tr("Image Files (*.png *.jpg *.bmp *.jpeg);;All Files (*)"));
    if (!fileName.isEmpty()) {
        cv::Mat loadedImage;
        if (imageProcessor->openImage(fileName.toStdString(), loadedImage)) {
            currentImage = loadedImage.clone(); // Clone loaded image
            displayImage(currentImage);
        }
        else {
            QMessageBox::critical(this, tr("Error"), tr("Failed to open image file"));
        }
    }
}

void MainWindow::saveFile()
{
    if (!currentImage.empty()) {
        QString filePath = QFileDialog::getSaveFileName(this, tr("Save Image"), "", tr("Images (*.png *.jpg *.bmp)"));
        if (!filePath.isEmpty()) {
            if (!imageProcessor->saveImage(filePath.toStdString(), currentImage)) {
                QMessageBox::critical(this, tr("Error"), tr("Failed to save image"));
            }
        }
    }
    else {
        QMessageBox::critical(this, tr("Error"), tr("No image to save"));
    }
}

void MainWindow::rotateImage()
{
    if (!currentImage.empty()) {
        auto future = imageProcessor->rotateImage(currentImage);
        future.waitForFinished();
    }
}

void MainWindow::zoomInImage()
{
    if (!currentImage.empty()) {
        scaleFactor = 1.25;
        auto future = imageProcessor->zoomImage(currentImage,
            scaleFactor);
        future.waitForFinished();
    }
}

void MainWindow::zoomOutImage()
{
    if (!currentImage.empty()) {
        scaleFactor = 0.8;
        auto future = imageProcessor->zoomImage(currentImage,
            scaleFactor);
        future.waitForFinished();
    }
}

void MainWindow::convertToGrayscale()
{
    if (!currentImage.empty()) {
        auto future = imageProcessor->convertToGrayscaleAsync(currentImage);
        future.waitForFinished();
    }
}

void MainWindow::applyGaussianBlur()
{
    if (!currentImage.empty()) {
        bool ok;
        int kernelSize = QInputDialog::getInt(this, tr("Gaussian Blur"), tr("Enter kernel size (odd number):"), 5, 1, 101, 2, &ok);
        if (ok) {
            auto future = imageProcessor->applyGaussianBlur(currentImage, kernelSize);
            future.waitForFinished(); 
        }
    }
}

void MainWindow::detectEdges()
{
    if (!currentImage.empty()) {
        auto future = imageProcessor->detectEdges(currentImage);
        future.waitForFinished();
    }
}

void MainWindow::exitApplication()
{
    QApplication::quit();
}

void MainWindow::redoAction()
{
    if (imageProcessor->canRedo()) {
        imageProcessor->redo();
    }
}

void MainWindow::undoAction()
{
    if (imageProcessor->canUndo()) {
        imageProcessor->undo();
    }
}


void MainWindow::displayImage(const cv::Mat& image)
{
    QImage qImage(image.data,
        image.cols,
        image.rows,
        static_cast<int>(image.step),
        QImage::Format_BGR888);
    ui->label->setPixmap(QPixmap::fromImage(qImage));
    ui->label->adjustSize();
}


void MainWindow::connectActions()
{
    connect(ui->actionOpen, &QAction::triggered, this, &MainWindow::openFile);
    connect(ui->actionSave, &QAction::triggered, this, &MainWindow::saveFile);
    connect(ui->actionExit, &QAction::triggered, this, &MainWindow::exitApplication);

    connect(ui->actionRotate, &QAction::triggered, this, &MainWindow::rotateImage);
    connect(ui->actionZoomIn, &QAction::triggered, this, &MainWindow::zoomInImage);
    connect(ui->actionZoomOut, &QAction::triggered, this, &MainWindow::zoomOutImage);
    connect(ui->actionRedo, &QAction::triggered, this, &MainWindow::redoAction);
    connect(ui->actionUndo, &QAction::triggered, this, &MainWindow::undoAction);

    connect(ui->actionGrayscale, &QAction::triggered, this, &MainWindow::convertToGrayscale);
    connect(ui->actionGaussianBlur, &QAction::triggered, this, &MainWindow::applyGaussianBlur);
    connect(ui->actionDetectEdges, &QAction::triggered, this, &MainWindow::detectEdges);

    
}

void MainWindow::connectImageProcessor()
{
    // Connect ImageProcessor's signal to displayImage slot
    connect(imageProcessor, &ImageProcessor::imageProcessed, this, &MainWindow::displayImage);
}

void MainWindow::setInitialWindowGeometry()
{
    const int initialWidth = 800;
    const int initialHeight = 600;
    const int initialX = 100;
    const int initialY = 100;
    this->setGeometry(initialX, initialY, initialWidth, initialHeight);
}

